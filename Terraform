==================================================================Terraform and packer=====================================================================================

1 - what is terraform

>>Terraform version 1.4.0
>>Terraform it is open-source terrform is IAAC(Infrastructure as a code) tool used to create resources on cloud providers like AWS, Azure, GCP so on. 
>> For example if you want to create an ec2 instance using Terraform rather than going to the management console to click on service you will write a code 
>>using terraform is easy to manage the infrastructure you can reuse the code to create multiple resources you can also store the code on a version control system like
GitHub code commit bitbucket to keep track of your changes in resources 
>> Terraform is not easy but effective
>> When any changes happen .tfstate will save the data
>>tfstate is very important
>>you can apply single module if you want 

Advantages:-
1-Automated infra CRUD(create read update delete)
2-Terraform code is easy to understand and easy to use
3-Version control(we can save the code in git and easy to collaborate the other teammates)
4-terraform have an idempotant
5-Consistent Infra(using terraform code you can create similar infra into different environment without duplicate)
6-Config can be split into multiple files (variables)
7-Inventory management
8-Cost optimization
9-Modular Infra(DRY -->Dont Repeat Yourself)
10-importing resource is easy
Dis-Advantages:-
1-Bugs will not be fixed (fast)
2-new service might not be available(when aws developing an service when he relases aws services then he can develop the terraform )
3-his is a third-party tool (there is no support at all times and all the new services not availble)

#>>terraform is an infrastructure as a tool that allows you to build infrastructure and change versions,safely and efficently
#>>Terraform is a tool for building, changing and versioning infrastructure safely and efficiently. Terraform can manage existing and popular cloud service providers
#as well as custom in-house solutions.Configuration files describe to Terraform the components needed to run a single application or your entire datacenter

2-is it terraform cloud aganstics

>>terraform is cloud aganstic  -->yes terraform will work every cloud but the code is difference that why we calling cloud aganstics

3-what is proprietory

>>it is like not a open-source when you using terraform you advised some code to then can verfiy and give resopnce 
but in aws your rasing an ticket but its take some time to contact and its not accept your advise this proprietory

4-what is the differnce between argument refernce and attribute refernce in terraform

>>In Terraform, attributes and arguments are two important concepts used to define and configure resources.

>>Arguments: Arguments are used to define the configuration for a resource. They are the input values that define the desired state of the resource. For example, when defining an 
EC2 instance, arguments might include the instance type, AMI ID, security group, and key pair.
>>Attributes: Attributes are the output values that are returned by a resource after it has been created or updated. They represent the current state of the resource and can be used
by other resources or modules. For example, an EC2 instance might have attributes such as the public IP address, private IP address, and instance ID.
>>In general, arguments are used to define the desired state of a resource, while attributes are used to retrieve the current state of a resource. By using attributes and arguments in
Terraform, you can define and manage your infrastructure in a more modular and reusable way.

5-how to deploy dev environment and prod environment in a single folder 

>>yes you can use workspace usinng you can deploy the devand prod environmet by chnaging code in dev.tfvars and prod.tfvars by chnaging workspace context
there is chance to overwrite the environmet in case if you do mistake so need to be carefully. either you can seprate folders is good in production environment
>>terraform apply --var-file prod.tfvars --auto-approve       -->it will execute the prod.tfvars in prod workspace
>>terraform apply --var-file dev.tfvars --auto-approve        -->it will execute the dev.tfvars in dev workspace

6-what is splat syntax in terraform and element ,functions,

>>splat syntax if the resource has a count attributes set you can access individual attributes with a zero-based 
index such as ${aws_instance.web.0.id} you can also use the splat syntax to get a list of attributes ${aws_instance.web.*.id}

>>if you want use subnet_id = aws_subnet.public-subnets[0].id   first subnets then like this it will satrt 0 until you mention like this ${count.index +1}" it will start 1 then 2 then 3 
 
>>functions using we can do duplicate the code
>>element idicates when you give the index in terraform it indicates starts from 0 
>>index is count

7-what is concat

>>concat takes two or more lists and combines them into a single list.

--How do I merge two lists in Terraform?

>>You can use terraform concat() function to combine multiple lists into a single list. concat() takes two or more lists and combines them into a single list.

variable "bucket_prefix" {
  default = "my-bucket-prefix"
}

variable "dynamic_value" {
  default = "123"
}

variable "bucket_suffix" {
  default = "mysuffix"
}

resource "aws_s3_bucket" "example_bucket" {
  bucket = "${concat(var.bucket_prefix, "-", var.dynamic_value, "-", var.bucket_suffix)}"

  acl    = "private"
  # other AWS S3 bucket configurations...
}

8-Define null resource in Terraform.

>>null_resource is used to run the resources using which present the resource using we can create the new resouces
>>A null resource is basically something that doesn't create anything on its own, but you can use it to define provisioners blocks. They also have a “trigger” attribute, which can 
be used to recreate the resource, hence to rerun the provisioner block if the trigger is hit.

>>if your using null resource your trigger first time then it will trigger the instance that remote exec or local exec will trigger if you do second time it will trigger but will not execute . why means 
either id or remote exec file need to change eitheriwise it will not work 
>>ex:-

resource "aws_instance" "web" {
  ami                    = data.aws_ami.centos8.id
  instance_type          = "t3.micro"
  vpc_security_group_ids = [aws_security_group.allow_tls.id]

  tags = {
    Name        = "web"
    environment = "DEV"
  }

}

resource "null_resource" "provision" {

  triggers = {
    instance_id = aws_instance.web.id
  }

  provisioner "remote-exec" {
    connection {
      host     = aws_instance.web.public_ip
      user     = "centos"
      password = "DevOps321"
    }

    inline = [
      "echo Helo"
    ]
  }
}

9-what is local-exec and remote-exec

>>local-exec provisioners. The local-exec using we can retrive or take information from the terraform deployment code and see. where you are executed 
terraform we can use this in local-exec command and write some details to see without going to aws you can see your system terraform folder

>>remote-exec provisioner is used it will login to your server run your commands inside the server and execute that files inside the server

10-what is for_each and count how to use in terraform and how many types of variables and what is variables 

>>count is using create multiple resources instances according to the count
>>The count argument is used to determine the amount of instances to create for a particular resource. The count argument can be used in both a module as well as every resource type
>>count is good if there is not change in the list index and changes are sequentical/leanier. any changes in the existing index will for the resource to recreate

resource "aws_subnet" "public-subnets" {
    count = "${var.environment == "prod" ? 3 : 2}"
    vpc_id = "$element{aws_vpc.default.id}"
    cidr_block = "${element(var.public-cidrs, count.index)}"
    availability_zone = "${element(var.azs, count.index)}"

    tags = {
        Name = "$element{aws_vpc.default.tags.name}-public-subnet-${count.index + 1}"
    }
}

ex;-
docdb = {
  main = {
    vpc_name            = "main"
    subnets_name        = "db"
    engine_version      = "4.0.0"
    number_of_instances = 1
    instance_class      = "db.t3.medium"
  }
}

rds = {
  main = {
    vpc_name            = "main"
    subnets_name        = "db"
    engine              = "aurora-mysql"
    engine_version      = "5.7.mysql_aurora.2.11.1"
    number_of_instances = 1
    instance_class      = "db.t3.small"
  }
}

module "docdb" {
  source = "github.com/raghudevopsb70/tf-module-docdb"
  env    = var.env

  for_each            = var.docdb
  subnet_ids          = lookup(lookup(lookup(lookup(module.vpc, each.value.vpc_name, null), "private_subnet_ids", null), each.value.subnets_name, null), "subnet_ids", null)
  vpc_id              = lookup(lookup(module.vpc, each.value.vpc_name, null), "vpc_id", null)
  allow_cidr          = lookup(lookup(lookup(lookup(var.vpc, each.value.vpc_name, null), "private_subnets", null), "app", null), "cidr_block", null)
  engine_version      = each.value.engine_version
  number_of_instances = each.value.number_of_instances
  instance_class      = each.value.instance_class
}

module "rds" {
  source = "github.com/raghudevopsb70/tf-module-rds"
  env    = var.env

  for_each            = var.rds
  subnet_ids          = lookup(lookup(lookup(lookup(module.vpc, each.value.vpc_name, null), "private_subnet_ids", null), each.value.subnets_name, null), "subnet_ids", null)
  vpc_id              = lookup(lookup(module.vpc, each.value.vpc_name, null), "vpc_id", null)
  allow_cidr          = lookup(lookup(lookup(lookup(var.vpc, each.value.vpc_name, null), "private_subnets", null), "app", null), "cidr_block", null)
  engine              = each.value.engine
  engine_version      = each.value.engine_version
  number_of_instances = each.value.number_of_instances
  instance_class      = each.value.instance_class
}

this can be solved by for_each bcoz it uses key rather than

>>for_each using you can create multiple instances accroding to the map, or set of strings

11-what is modules in terraform 

>>A Terraform module is a set of Terraform configuration files in a single directory. Even a simple configuration consisting of a single directory with
one or more .tf files is a module. When you run Terraform commands directly from such a directory, it is considered the root module.

>>if you created modules anyone can use this why because module will be same you need to change the values what need to change you can pass that modules file to anyone then that person can change
the values they can use variables to pass the values 
>>modules is using we can use code many times
>>modules using you can source the files you can use github repository also
>>modules using ./main.tf file another tab also
>>it is repetable code.one code you can use number of times

module "virtual_network" {
source = "./modules/virtual_network"
// other variables... #here you can mention what changes you need  
}

12-what is terraform life cycle, Imports , terraform cloud 

---Life cycle:-
>>create_before_destroy
--if your created an s3 or any system but your created wrong bucket or wrong vpc this logs have store in vpc flow logs
but you dont want lose that dat on that you use create_before_destroy and then your write a code to
copy the files to some other bucket store the data 

>>prevent_destroy
--if your createdan s3 bucket are any vpc or any ec2 system or anything no one want to delete you can use 
this prevent_destory 

lifecycle {
prevent_destory = true
}

>>ignore_changes
--if deployed some instance using terraform but your changed some of the tags or some data change 
maually but in terraform you need to use ignore_changes then the the cant destory what you changed manually

lifecycle {
ignore changes = [
 tags,enable_dns_hostname
]
}

13-what is terraform Imports?

>>terraform Imports:-
---when we have mistkaley or already deployed server in ec2 any service you need import that service
using terraform command you can take the code command to copy the the code code into .tf file

commands:-

>>terraform import aws_instance.importing "instance-id from the aws"
>>terraform state list
>>terraform state show aws_instance.importing          -->you will get code copy and paste below your code page

resource "aws_instance" "importing" {

paste that copy that data

}

14-what is terraform-cloud

>>What is Terraform Cloud? Terraform Cloud is HashiCorp's managed service offering. It eliminates the need for unnecessary tooling and
documentation for practitioners, teams, and organizations to use Terraform in production. Provision infrastructure in a remote environment 
that is optimized for the Terraform workflow.

What is Terraform cloud used for?
Terraform Cloud enables infrastructure automation for provisioning, compliance, and management of any cloud, datacenter, and service

15-what is packer

>>packer is used to create only images
>>Packer is an open-source VM image creation tool from Hashicorp. 
It helps you automate the process of Virtual machine image creation on the cloud and on-prem virtualized environments.

16-what is terraform dry-run

>>Dry runs help you identify trouble spots, discover sections you may not fully understand, and get a better understanding of how everything fits together.
It's also a good way to find out if you don't fully understand how an activity is supposed to be conducted or how the virtual tools function.

17-What are the most useful Terraform commands?

terraform init - initializes the current directory
terraform refresh - refreshes the state file
terraform output - views Terraform outputs
terraform apply - applies the Terraform code and builds stuff
terraform destroy - destroys what has been built by Terraform
terraform graph - creates a DOT-formatted graph
terraform plan - a dry run to see what Terraform will do

18-What are some of the built-in provisioners available in Terraform?

Salt-masterless Provisioner
Remote-exec Provisioner
Puppet Provisioner
Local-exec Provisioner
Habitat Provisioner
File Provisioner
Chef Provisioner

19-What is terraform taint and untaint?

>>the commands comes under terrafomr forcing recreation of resources
>>terraform taint command manually marks a terraform-managed reosuce as tainted forcing it to be destroyed and recreated on the next apply
>>terraform untaint command manually umarks a terraform managed resource as tainted restoring it as the primary instance in the state

>>terraform state list
>>terraform taint "resource-name"
>>terraform taint aws_instance.my-ec2-vm-new
>>terraform plan
>>terraform apply --auto-approve
>>terraform untaint aws_instance.my-ec2-vm-new
>>terraform plan
>>terraform state mv anji.sh sampi.sh

20-what is the use of provisoners in packer and terraform

>>Terraform Provisioners are used for executing scripts or shell commands on a local or remote machine as part of resource creation/deletion. 
They are similar to “EC2 instance user data” scripts that only run once on the creation and if it fails terraform marks it tainted

21-What is a tuple Terraform?

>>A tuple is a strongly typed collection of one or more values. So, for example, we could define a tuple of three values: string , number , number , 
or two values: string ,string . Once a tuple is defined, it always has to contain the number of values defined in that tuple.

22-what is .tfstate in terraform

>>when your deploying any resources it will save your code in .tfstate file if any changes happen in code it will go and check the .tfstate file and it will change 
what need to chnage the resources. it will idempotant so it update the resource what changed only that resources change not changed all the rsources

23-is it possible to execute the dev.tfvars and prod.tfvars

>>No if you executed first dev.tfvars and later add prod.tfvars it will think need to change the .tfvars and destroy your first dev.tfvars and add into prod.tfvars 
so dont use this method you can use the instead of WorkSpaces. if your using workspace but inside prod workspace if your using the dev.tfvars  it will destroy the 
prod environment so be careful when you using the workspace

24-how you can give to other devlopers terraform.tfstate

>>when we deploying the code onthat time we saving the terraform.tfstate file in s3 bucket or any version control system then we can give that terraform.tfstae to
other developer he can easily understand the situvation and he can do chnages then the state file update when we can changes on that time we can use that
terraform.tfstate to avoid the complications and any errors or misunderstandings. so when the runing the backend it will run first backend so its give an error
need to add access-key and secret-key in your system. it will not take the access and secret key in your var.tf

25-what is lookup in terraform

>>The lookup() function can be used to lookup a particular value inside of a map , given its key and if the given key does not exist, the given default value is 
returned instead: lookup(map, key, default)

26-what is triggers

>>A map of values which should cause this set of provisioners to re-run values are mean to interpolated refernace varibales to attributes of other resources

27-what is DNS_Hostnames

>>For example, when a Web address (URL) is typed into a browser, a DNS query is made to learn an IP address of a Web server associated with that name. 
Using the www.example.com URL, example.com is the domain name, and www is the hostname. DNS resolution maps www.example.com into an IP address (such as 192.168.2.10)

28-what is variable

>>giving name to storage location. variable is a great way to define centrally controlled reusable values

29-what is terraform data-sources

>>Terraform data sources let you dynamically fetch data from APIs or other Terraform state backends. Examples of data sources include machine image IDs from a 
cloud provider or Terraform outputs from other configurations.

data "aws_instance" "anji" {
  instance_id = "i-78vula7*jkba"
}

output "instance" {
  value = data.aws_instance.anji.public_ip
} ##this will fecth the public ip of your instance only

30-what is terraform functions

>>The Terraform language includes a number of built-in functions that you can call from within expressions to transform and combine values. 
The general syntax for function calls is a function name followed by comma-separated arguments in parentheses: max(5, 12, 9)map

1-concat
2-element
3-join
4-map
5-slice
6-format
7-file
8-lookup
9-replace
10-max
11-min
12-timeadd
13-floor

31-what is dynamic blocks in terraform

>>Terraform provides the dynamic block to create repeatable nested blocks within a resource. A dynamic block is similar to the for expression. Where for creates 
repeatable top-level resources, like VNets, dynamic creates nested blocks within a top-level resource, like subnets within a VNet.

32-what is teraform lock file

>>terraform. lock. hcl , and this name is intended to signify that it is a lock file for various items that Terraform caches in the . terraform subdirectory of your
working directory. Terraform automatically creates or updates the dependency lock file each time you run the terraform init command.
>>it .terraform.lock.hcl holdes the version of AWS code and hashes version

33-what is terraform count

>>To manage several of the same resources, you can use either count or for_each , which removes the need to write a separate block of code for each one.

34-what is Terraform state locking 

>>any two developers working on same state you an able lok that file then second person get an error to avoid duplications. your mentiong in the backend file like 
s3 where s3 storing on that your mentioning and that will dynamodb lock the partition key must be LockID
>>you can loack that file 1 hour or 2 hours also example 
terraform {
  backend "s3" {
    bucket         = "your-s3-bucket"
    key            = "path/to/terraform.tfstate"
    region         = "your-aws-region"
    dynamodb_table = "terraform_lock_table"
    encrypt        = true
    acl            = "private"
  }
}

locals {
  lock_duration_hours = 1
}

35-what is terrafomr depends-on

>> Using depends_on you cna create the resources like you want create the vpc then after need to create the subnet then you can use the depends-on then it will
create when vpc created after it will create the reaming resource
depends_on = {
aws_vpc.default
}

36-when you created vpc and route tables using terrform and the data will be stored .tfstate file some one came and delete the route table it will recreate route table one more time

>>yes it will recreate the route table the data is stored in .tfstate so when some one deleted it will automatically created 

37-if you want apply one one instance or one module only how can you apply in terraform

>>terraform apply --target=module.vpc

38-my clinet is asking to setup same infra in 3 or 4 regions using same code and dont duplicate at a time need to execute what we can do

>>you cna do this way 
provider "aws" {
 region = "ap-south-1"
 region = "us-east-1"
 region = "us-east-1"
} 
>>if you want use ami means you need to use true or false because ami will be differnet in other regions

variable "ami" {
  description = "AMIs by region"
  default = {
    ap-south-1 = "ami-024c319d5d14b463e"
    us-east-1 = "ami-0149b2da6ceec4bb0"
  }
}

39-is this possible to do same configuration in another aws account

>>yes it possible to do using variables

40-You have a Terraform configuration file that defines an infrastructure deployment. However, there are multiple instances of the same resource that need to be created.How would you modify the configuration file to achieve this..??

>>To create multiple instances of the same resource in Terraform, you can utilize the count or for_each meta-arguments in your configuration file.

count:-
resource "aws_instance" "example" {
  count = 3

  # Configuration for each instance
  ami           = "ami-abc123"
  instance_type = "t2.micro"

  # Unique tags for each instance
  tags = {
    Name = "Instance ${count.index}"
  }
}

for_each:-
variable "instances" {
  type = map(object({
    ami           = string
    instance_type = string
  }))
  default = {
    "instance1" = {
      ami           = "ami-abc123"
      instance_type = "t2.micro"
    },
    "instance2" = {
      ami           = "ami-def456"
      instance_type = "t2.small"
    }
  }
}

resource "aws_instance" "example" {
  for_each = var.instances

  # Configuration for each instance
  ami           = each.value.ami
  instance_type = each.value.instance_type

  # Unique tags for each instance
  tags = {
    Name = each.key
  }
}

41-What exactly is Sentinel? Can you provide few examples where we can use for Sentinel policies..?

>>Sentinel is a policy-as-code framework developed by HashiCorp. It enables the implementation of fine-grained, automated policy enforcement for infrastructure provisioning and
deployment using Terraform. Sentinel policies help enforce security, compliance, and operational best practices.
>>Sentinel is terraform cloud or enterprise will provide restrict some types like instance types tags cost optimization easy way to build your infrastructure

1-Security Policies
2-Compliance Policies
3-Cost Optimization
4-Naming Conventions
5-Governance and Best Practices

42-How do you manage sensitive data in Terraform, such as API keys or passwords..?

1-Input Variables with Sensitive Flag
2- Environment Variables
3-External Secret Management Tools
4-Terraform Cloud: If you're using Terraform Cloud, you can set sensitive variables directly in the workspace. These variables are stored securely and only provided to runs as needed.
5-Vault: For a more sophisticated solution, you could use HashiCorp's Vault. Vault is a tool for securely managing secrets, and it integrates with Terraform.
	
43-Below command will destroy everything that is being created in the infrastructure. Tell us how would you save any particular resource while destroying the complete infrastructure.

>>When executing the terraform destroy command, it will remove all the resources created by Terraform and destroy the infrastructure. 
If you want to save a particular resource from being destroyed, you can use Terraform's resource lifecycle management feature.
>>To save a specific resource, you can modify the resource block in your Terraform configuration file by adding the lifecycle block and setting the prevent_destroy argument to true. 
This prevents Terraform from destroying that specific resource during the execution of terraform destroy
resource "aws_instance" "example" {
  # Resource configuration...

  lifecycle {
    prevent_destroy = true
  }
}

44-What are the main competitors of terraform list and describe them.

1-AWS CloudFormation
2-Azure Resource Manager (ARM) Templates
3-Google Cloud Deployment Manager
4-Ansible
5-Puppet

45-Define purpose of basic Terraform commands which you’ll use often

1-terraform init: Initializes a Terraform working directory. It downloads the necessary provider plugins and sets up the backend configuration.
2- terraform init -upgrade: Upgrades the Terraform modules and providers to the latest available versions, ensuring you have the most up-to-date features and bug fixes.
3-terraform plan: Creates an execution plan by comparing the current state of the infrastructure with the desired state defined in your Terraform configuration. 
It shows you the changes that Terraform will make without actually applying them.
4-terraform apply: Applies the changes defined in your Terraform configuration to create, modify, or delete resources. It prompts for confirmation before making any modifications.
5-terraform validate: Validates the syntax and configuration of your Terraform files. It checks for any errors or warnings in your code without making any changes to your infrastructure.
6-terraform fmt: Formats your Terraform configuration files to ensure consistent and readable code style. 
It automatically rearranges and indents the code according to the Terraform style guide.
7-terraform destroy: Destroys all the resources created by Terraform, effectively tearing down your infrastructure. It prompts for confirmation before removing the resources.

46-What is the Resource..??

>>In Terraform, a resource is a single entity in your infrastructure that you want to manage using Terraform. It could be a virtual machine, a database, a network interface, or any other
component that you want to provision, configure, or manage. A resource is defined using a Terraform configuration block that specifies the resource type, attributes, and dependencies.

47-What is Desired and Current State..?

>>In the context of infrastructure management tools like Terraform, the desired state refers to the configuration or specification of how the infrastructure should look like. 
It defines the intended state of resources, such as servers, networks, and databases, in terms of their properties, relationships, and settings.

>>On the other hand, the current state represents the actual state of the infrastructure at a given point in time. It reflects the existing resources, their attributes, and the 
relationships between them.

48-what are the functions you are using

>>joint
>>lookup
>>file

49-Is Terraform is mutable or immutable

>>terraform is mutable >>A mutable object can be changed after it's created, and an immutable object can't.

50-what is HCL(Hashicorp Conffiguration Language)

>>Hashicorp Configuration Language

51-what is terraform state mv command in 

>>>>terraform state mv command is used to rename existing resources and move a resource into a module and move a module into a module
>>if you were to just rename a resourcce or move it to another module and run terraform terraform apply will destroy and recraete the resource.
state mv allows you to just change the reference so you ccan avoid a create and destroy action

>>terraform state mv packet_device.worker packet_device.helper

52-what is terraform locking versions in different people in same team

>>your developed infrastructure using AWS version 3.74.0 all the infrastructure developed you pasted the code in github .tfstate some other person came and downloaded and the person is
intialized the code the AWS version 4.1.0 it may get an error right
so we can overcome this by using terraform locking version
>>if another person using different version this will make errors code will not work properly
>>if your not shared this lock.hcl file to other persons that may get error you need to validate the documentation everytime

terraform {
  required_providers {
    aws = {
      source = "hashicorp/aws"
      version = "3.47.0"
      version = ">=3.47.0"   ##it will use latest version
      version = "<=3.47.0"   ##it will use 3.47.0 below version
      version = "~>3.47.0"   ##any one in the range 3.47.99 something it will not go or work this up versions 3.48.0 

    }
  }
}

53-your state is locked another person how he can use that file statefile

>>you can use certain locck time for backend file
terraform {
  backend "s3" {
    bucket         = "your-state-bucket"
    key            = "path/to/your/terraform.tfstate"
    region         = "us-east-1"  # Replace with your AWS region
    encrypt        = true
    dynamodb_table = "your-locking-table"
    lock_duration  = 1800  # Optional: Set lock duration (in seconds)
  }
}
or else 
Release Lock: After they are done, they should release the lock by running terraform destroy or terraform state unlock followed by terraform apply to ensure that the state file is not left locked.
>>terraform state unlock lock-id-1234567890    -->you will see the lock id in state file  -->The Terraform lock ID is typically displayed in the error message when you try to access a locked state file.
For example, if you try to run the terraform apply command and the state file is locked, you will see an error message like this: 
>>terraform state unlock -force lock-id-1234567890  

54-What would you do if you were working in a team and your Terraform operations were consistently failing due to state lock errors?

>>Consistent state lock errors imply that another operation is already in progress, or a previous operation failed and left the state locked. You can use the terraform force-unlock command to manually 
unlock the state. However, be careful, as forcing an unlock can potentially corrupt the state.

55-How would you securely manage a Terraform state file in a production environment?

>>For a production environment, the state file should be stored in a remote backend that supports encryption at rest. The backend should also support locking to prevent concurrent state operations.
The state file contains sensitive data, so it should be treated with the same level of care as any sensitive data.

56-What is the impact on the state file when you run terraform destroy?

>>The terraform destroy command destroys all resources managed by Terraform in the state file and then updates the state file to indicate that no resources are managed. After running this command,
the state file will still exist, but it will not contain any managed resources.

57-Explain a scenario where you might need to use terraform state rm and its implications.

>>The terraform state rm command removes items from the Terraform state. It does not destroy the actual infrastructure resource, just removes it from Terraform management. 
You might use this command when a resource has been manually deleted, and you need to reconcile the state file to match the actual infrastructure.

58-In what scenario might you need to use terraform state list and what information does it provide?

>>The terraform state list command is used to list all resources in the current state file. This can be helpful if you need to get an overview of all resources managed by Terraform, 
especially in large deployments.

59-If you accidentally deleted your Terraform state file, how would you recover?

>>If versioning is enabled on the remote state backend, you can recover a deleted state file by restoring the most recent version. If you're not using versioning or a remote backend, 
it's significantly harder to recover unless you have a backup of the state file. This highlights the importance of state file backups and using versioned remote backends.

60-Can you explain how the terraform taint command affects the state file?

>>The terraform taint command marks a resource as tainted within the state file. A tainted resource will be destroyed and recreated during the next terraform apply.
This can be useful if you know a specific resource has an issue and needs to be recreated.

61-Describe a situation where you'd use a map or list variable in Terraform and provide an example.

>>Map and list variables are useful in Terraform when we need to pass complex data structures as input to modules or to define repeated similar resources. 
For instance, let's say we are creating multiple Azure storage accounts with different names and locations. We can use a map variable for this purpose.

variable "storage_accounts" {
description = "Map of all storage accounts and their properties" type = map(object({
name  = string location = string
}))
default = {

account1 = { name = "account1", location = "West Europe" } account2 = { name = "account2", location = "North Europe" }
}

}
resource "azurerm_storage_account" "example" { for_each = var.storage_accounts
name	= each.value.name location	= each.value.location
resource_group_name = azurerm_resource_group.example.name account_tier	= "Standard"
account_replication_type = "GRS"

}

62-how you can pass the output value to another resource

# Define your AWS provider configuration here
provider "aws" {
  region = "us-east-1" # Replace with your desired AWS region
}

# Create an EC2 instance
resource "aws_instance" "example" {
  ami           = "ami-XXXXXXXXXXXXXXXXX" # Replace with your desired AMI ID
  instance_type = "t2.micro"              # Replace with your desired instance type
  # Add any other instance configuration here
}

terraform init
terraform apply

# ...

output "public_ip" {
  value = aws_instance.example.public_ip
}
terraform apply

# Define your AWS provider configuration here
provider "aws" {
  region = "us-east-1" # Replace with your desired AWS region
}

# Create a Route 53 record set
resource "aws_route53_record" "example" {
  zone_id = "YOUR_ZONE_ID" # Replace with your Route 53 hosted zone ID
  name    = "example.com" # Replace with your desired DNS name
  type    = "A"
  ttl     = "300"         # Replace with your desired TTL
  records = [aws_instance.example.public_ip]
}

63-Imagine you have different variable values for different stages (dev, test, prod) of your infrastructure. How would you structure your Terraform configurations to make it easy to apply changes to a
specific stage?

>>One common way to handle this is to use separate Terraform workspace for each environment and have a corresponding variable file for each workspace. 
You can use workspace-specific variable files (dev.tfvars, test.tfvars, etc.) and apply them with the -var-file flag.

64-You are managing a complex infrastructure with many interdependent resources. How would you use output variables to expose necessary data (like IP addresses, DNS names, etc.) for use in other
configurations or modules?

>>Output variables can be used to expose data from one module to another, or to the root module. By using outputs, the necessary data will be displayed in the console after running terraform apply. 
If the state is stored remotely, the output values can also be queried using terraform output command.

65-What is the difference between local values and input variables in Terraform? When might you use one over the other?

>>Both local values and input variables in Terraform can be used to assign a name to an expression, so it can be reused. The main difference is that input variables are parameters for a module, 
while local values are only within the module where they are defined. You might use local values for temporary complex objects or when a value is repeated many times, 
to make the configuration more DRY (Don't Repeat Yourself).

66-You run terraform apply, and it fails with an error that the resource you're trying to create already exists. What could be the cause, and how would you solve it?

>>This issue usually arises when the Terraform state file does not reflect the actual infrastructure. The resource might have been manually created or managed by a different Terraform state file. 
One way to resolve this is by importing the resource into the current Terraform state using terraform import.

67-After running terraform plan, you notice that Terraform intends to recreate a resource even though you haven't made any changes to its configuration. What might cause this, and how would you handle it?

>>This could be due to some default values in the resource configuration that Terraform doesn't correctly identify as unchanged, or external changes that Terraform picked up during refresh.
To understand why Terraform wants to recreate the resource, you can use the -detailed-exitcode flag with terraform plan which will provide more information about what's changing.

68-You've made some changes to your Terraform configuration, but when you run terraform plan, it's showing a much larger set of changes than you expected. How would you determine what's causing these extra changes?

>>It could be due to a number of factors like implicit dependencies, changes in default values, etc. You could examine the output of terraform plan to see which resources it's intending to change and why.
You might also find the terraform graph command useful to visualize dependencies between resources.

69-You're running terraform apply in an automated CI/CD pipeline, and it fails with a timeout error while waiting for a resource to be created. What steps could you take to address this issue?

>>This could be addressed by adjusting the timeout settings in your Terraform configuration, using the timeouts block. You could also investigate whether there are any issues with the cloud provider 
that's causing resource creation to take longer than expected.

70-A Terraform module you're using from the Terraform Registry is causing errors during terraform apply. What steps can you take to investigate and resolve this issue?

>>You can review the module's documentation and source code to try to understand what might be causing the issue. Check the module's issue tracker for similar problems reported by others.
If you can't find a solution, consider raising a new issue on the tracker.

71-Terraform fails during planning with an error message "Error: Reference to undeclared resource". How would you fix this?

>>This error occurs when your configuration refers to a resource that Terraform doesn't know about. This could be due to a typo in the resource name, or the resource not being declared in your configuration.
Ensure that the referred resource is correctly declared in your configuration.

72-When applying a Terraform configuration, you receive an error that a required attribute is missing, but you see it defined in your configuration. What could be happening here?

>>This might be due to the attribute being in the wrong block or being incorrectly named in your configuration. Verify that the attribute is correctly named and placed according to the resource's documentation.
Also, check for syntax errors or incorrect variable references.

73-You made changes to your Terraform configuration, but when you run terraform plan, it doesn't detect any changes. What might be happening?

>>This could be due to a syntax error in your configuration causing Terraform to not recognize your changes, or your changes might not actually result in any changes to the infrastructure.
Check your configuration for syntax errors and verify that your changes should result in changes to the infrastructure.

74-When working with multiple Terraform workspaces, you receive an error that a resource already exists. How would you investigate this?

>>Check to make sure you're in the correct workspace by running terraform workspace show. Resources can overlap between workspaces if they're not differentiated in some way. 
Consider using the workspace name in your resource names to avoid collisions between workspaces.

75-Can you describe a scenario where you might need to manually edit a Terraform state file? What are the risks?

>>Manually editing a Terraform state file is highly discouraged. The state file contains crucial information about the infrastructure managed by Terraform, and any discrepancies between the 
actual infrastructure and the state file can cause significant problems. In cases where manual intervention is unavoidable, such as when a resource has been manually deleted, terraform taint or
terraform import are safer alternatives to direct state manipulation.

76-How does Terraform handle state locking, and how does it prevent conflicts in a team environment?

>>State locking is a feature of Terraform that locks the state file when an operation is being performed, preventing others from running Terraform commands that could interfere. 
This prevents conflicts in the state file and ensures consistency. State locking is available with certain backends that support it, such as the S3 backend when used with DynamoDB.

77-If you are working on multiple separate Terraform projects, how can you ensure that the state files don't get mixed up?

>>To manage the state files for separate projects, you can use separate backends for each project or use the workspace feature of Terraform. Workspaces allow you to have separate state files in the 
same backend, effectively separating resources between environments or projects.

78-Describe a situation where you would use remote state in Terraform.

>>Remote state is particularly useful when working as part of a team or when you need to keep the state of your infrastructure secure yet accessible. Remote state allows the state data to be stored 
in a remote data store, such as AWS S3, Azure Blob Storage, Google Cloud Storage, and others. This ensures everyone on the team has access to the latest state of the infrastructure.

79-What command would you use to pull the latest state file, and why might you need to do this?

>>You can use the terraform refresh command to update the local state file against the real resources. This is useful to ensure the state file accurately represents the real- world resources, especially 
when changes might have been made outside of Terraform.

80-What strategies can you use to mitigate the risk of state file corruption or loss?

>>Using a remote backend that supports versioning can help prevent loss or corruption of the state file. Versioning allows you to roll back to a previous version if something goes wrong. Additionally, 
regular backups of the state file are also a good practice to recover from accidental deletion or corruption.

81-How would you handle a situation where your local Terraform state is out of sync with the actual infrastructure?

>>If the local state is out of sync, you might use the terraform refresh command to update the local state file with the actual infrastructure's state. 
This command queries the providers for each resource's actual status and updates the state file accordingly.

83-You need to install or copy specific software on an AWS EC2 instance after it's created. How would you achieve this using provisioners?

resource "aws_instance" "private-instances" {
    count = "${var.environment == "prod" ? 3 : 1}"
    ami = "${lookup(var.amis, var.aws_region, "ap-south-1")}"
    instance_type = "t2.micro"
    key_name = "chefkeypair"
    subnet_id = "${element(aws_subnet.private-subnets.*.id, count.index)}"
    vpc_security_group_ids = ["${aws_security_group.allow_all.id}]
    #associate_public_ip_address = true
    tags = {
        Name = "private-server-${count.index+1}"
    }
}
resource "null_resource" "execute" {
depends_on = [aws_instance.public-instances]
    connection {
        type = "ssh"
        host = aws_instance.foo.public_ip
        user = "ubuntu"
        private_key = "${file("test.pem")}"
    }
    provisioner "file" {
    source      = "anji.sh"
    destination = "/tmp/anji.sh"
  }

  provisioner "remote-exec" {
    inline = [
      "chmod +x /tmp/anji.sh",
      "/tmp/anji.sh",
    ]
  }

    provisioner "local-exec" {
    command = "echo '${aws_instance.foo.public_ip}' > instance_ip.txt"
    }
    provisioner "remote-exec" {
        inline = [
        "sleep 60",
        "sudo apt-get update -y",
        "sleep 20",
        "sudo curl https://get.docker.com | bash",
        "docker pull mongo", 
        "sudo docker run -d -p 27017:27017 -e username=mongoadmin -e mongo_password=password -e mango_database=test  mongo",
        "docker ps",
        ]
    }  
}

84-how to open all ports incomming ports using terraform 

ingress = [
  for port in [20, 80, 443, 8080, 9000] : {
    description   = "inbound rules"
    from_port     = port
    to_port       = port
    protocol      = "tcp"
    cidr_blocks   = ["0.0.0.0/0"]
    ipv6_cidr_blocks = []
    prefix_list_ids = []
    security_groups = []
    self            = false  
  }
] 


ingress {
    from_port   = 0
    to_port     = 65535
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  } 
single port only 
ingress {
    description = "http"
    from_port = 80
    to_port = 80 
    protocol = "tcp"
    cidr_blocks = ["0.0.0.0/0"]

}
egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1" 
    cidr_blocks = ["0.0.0.0/0"]
  }

85-how to configure secuirty group of instance anji system will access the sampi instance using secuirty grup using terrfform

# aws_setup.tf

provider "aws" {
  region = "your_aws_region"
}

# Security Group for Anji instance
resource "aws_security_group" "anji_security_group" {
  name        = "anji-se"
  description = "Security group for Anji instance"

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

# EC2 Instance for Anji
resource "aws_instance" "anji_instance" {
  ami           = "your_ami_id"  # Specify the AMI ID for your region
  instance_type = "t2.micro"
  key_name      = "your_key_pair_name"  # Replace with your key pair name

  security_group = [aws_security_group.anji_security_group.id]

  tags = {
    Name = "anji-instance"
  }
}

# Security Group for Sampi instance
resource "aws_security_group" "sampi_security_group" {
  name        = "sampi-se"
  description = "Security group for Sampi instance"

  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    security_groups = [aws_security_group.anji_security_group.id]
  }
}

# EC2 Instance for Sampi
resource "aws_instance" "sampi_instance" {
  ami           = "your_ami_id"  # Specify the AMI ID for your region
  instance_type = "t2.micro"
  key_name      = "your_key_pair_name"  # Replace with your key pair name

  security_group = [aws_security_group.sampi_security_group.id]

  tags = {
    Name = "sampi-instance"
  }
}

////////////////////////////////////////////////////////////Second-type-multiple-security-groups//////////////////////////////////////////////////////////////////////

resource "aws_security_group_rule" "http_ingress_rule" {

  type              = "ingress"
  from_port         = 80
  to_port           = 80
  protocol          = "tcp"
  cidr_blocks       = ["0.0.0.0/0"]
}

resource "aws_security_group_rule" "ssh_ingress_rule" {
 
  type              = "ingress"
  from_port         = 22
  to_port           = 22
  protocol          = "tcp"
  cidr_blocks       = ["aws_security_group.sampi_security_group.id"]  # Replace <sampi_system_IP> with the actual IP address of Sampi system
}
# Security Group for Sampi instance
resource "aws_security_group" "sampi_security_group" {
  name        = "sampi-se"
  description = "Security group for Sampi instance"

  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks       = ["0.0.0.0/0"]
  }
}
##sampi system only take ssh possible 
resource "aws_instance" "anjis_instance" {
  ami           = "ami-xxxxxxxxxxxxxxxxx"
  instance_type = "t2.micro"
  associate_public_ip_address = false
  # Other instance configuration parameters...

  vpc_security_group_ids = [
    aws_security_group.http_ingress_rule.id,
    aws_security_group.ssh_ingress_rule.id,
    # Add other security groups as needed
  ]
}
##sampi system
resource "aws_instance" "sampi_instance" {
  ami           = "ami-xxxxxxxxxxxxxxxxx"
  instance_type = "t2.micro"
  associate_public_ip_address = true
  # Other instance configuration parameters...
  security_group = [aws_security_group.sampi_security_group.id]  
}

86-why IAC  -->Infrastructure As Code 

>>faster time to release 
>>Improved consistency,less configuration drift
>>faster, more efficient development
>>Lower costs and more time developing and fewer operations 

87-what are the terraform module types 

1-root module 
2-child module 
3-publish module 
4-

88-how to attach multiple security groups to ec2 inatnce 

vpc_security_group_ids = [
    "sg-xxxxxxxxxxxxxxxxx",  # Security Group 1
    "sg-yyyyyyyyyyyyyyyyy",  # Security Group 2
    "sg-zzzzzzzzzzzzzzzzz"   # Security Group 3
]

89-you have three system you need to get the public ip as output 

output "public_ip" {
  value = aws_instance.web.*.public_ip ##this will print two or three  public ips 
}

90-you need two instance one is t2micro another is t3.micro this need to execute single code using terraform

resource "aws_instance" "example_instance" {
  count = length(var.component)
  ami           = "ami-xxxxxxxxxxxxxxxx" # specify your AMI ID
  instance_type = "t2.micro"             # specify the instance type
  security_groups = [var.security_group_id]

  tags = {
    Name = var.component[count.index]#this will give cart and catalogue as name first one 
     
  }
}


variable "component" {
  value = ["cart", "catalogue"]
}


resource "aws_instance" "web" {
  for_each  = var.component
  ami           = "ami-xxxxxxxxxxxxxxxx" # specify your AMI ID
  instance_type = each.value.instance_type             # specify the instance type
  security_groups = [var.security_group_id]
  
  tags = {
    Name = each.value["name"]
  }
}

variable "component" {
  default {
    cart = {
      name = "cart"
      instance_type = "t3.micro"
    }
    catalogue = {
      name = "catalogue"
      instance_type = "t2.micro"
    }
  }
}

output "publicip" {
  value =aws_instance.web["cart"].public_ip ##this will get only cart public ip 
}

output "publicip" {
  value = {
    for k, v in aws_instance.web : k => v.public_ip  
    #it wil fecth the aws_instance.web under it will check the k=cart then check the public ip same for k=catalogue will be show the public ip 
  }
} 


variable "instances" {
  default = [
    {
      name          = "cart"
      ami           = "xxxxxxxxxxxxxxxxxxxx"
      instance_type = "t3.micro"
    },
    {
      name          = "catalogue"
      ami           = "xxxxxxxxxxxxxxxxxxxx"
      instance_type = "t2.micro"
    },
  ]
}

resource "aws_instance" "web" {
  for_each =  var.instances

  ami           = each.value.ami
  instance_type = each.value.instance_type

  tags = {
    Name = each.key
  }
}

if your using modules then like this 

mkdir module 
cd module 
vi main.tf 

resource "aws_instance" "web" {
  ami                = *************************
  instance_type      = var.instance_type

  tags = {
    Name = var.name 
  }

}
variable instance_type {}
variable name {}

:wq

cd ..
vi main.tf 

variable "component" {
  default = {
    cart = {
      name          = "cart"
      instance_type = "t3.micro"
    }
    catalogue = {
      name          = "catalogue"
      instance_type = "t2.micro" 
    }
  }
}

module "ec2" {
  source   = "./module"

  for_each   = var.component
  instance_type = each.value.instance_type
  name = each.value.name
}

output "publicip" {
  value = {
    for k, v in module.ec2 : k => v["ec2"].public_ip  
    #it wil fecth the aws_instance.web under it will check the k=cart then check the public ip same for k=catalogue will be show the public ip 
  }
} 

91-what is terraform local 

>>the big expression need to be used in multiple places and locals can help you keeping it one place and you refer with another simple variable 

locals {
  instance_type  = { for k, v in var.components : k => v.instance_type }
  name           = { for k, v in var.components : k => v.name }
}

output "instance_type" {
  value = local.instance_type
}

output "name" {
  value = local.name 
}

92-how to connect ec2 instance using terraform provisioners

resource "aws_instance" "example_instance" {
  ami             = "ami-xxxxxxxxxxxxxxxx" # Replace with your AMI ID
  instance_type   = "t2.micro"
  key_name        = "your_key_pair_name"   # Replace with your key pair name
  security_group_ids = ["sg-xxxxxxxxxxxxxxxx"] # Replace with your security group ID

  # Other instance configurations...

  provisioner "remote-exec" {

    inline = [
      "echo 'Hello, this command is running on the instance.'",
      "sudo apt-get update",
      # Add any other commands you want to execute on the instance
    ]

    connection {
      type     = "ssh"  ##you can username and password also 
      user     = "ubuntu" # Replace with your instance's default user
      private_key = file("path/to/your/private-key.pem") # Replace with the path to your private key
      host     = self.public_ip # Terraform's self variable to get the public IP of the instance
    }
  }
}

resource "null_resource" "provision" {
    triggers = {
      instance_id = aws_instance.example_instance.id  ##this will if the system restart or terminate then it will connect or do it again  
    }
      provisioner "remote-exec" {

    inline = [
      "echo 'Hello, this command is running on the instance.'",
      "sudo apt-get update",
      # Add any other commands you want to execute on the instance
    ]

    connection {
      type     = "ssh"  ##you can username and password also 
      user     = "ubuntu" # Replace with your instance's default user
      private_key = file("path/to/your/private-key.pem") # Replace with the path to your private key
      host     = self.public_ip # Terraform's self variable to get the public IP of the instance
    }
  }
}  

93-how to configure write a code to two differnet AWS account

aws configure --profile anji(prod)
access_key: *************************
secret_key: *************************
region: *****************

aws configure --profile sampi(dev)
access_key: *************************
secret_key: *************************
region: *****************
provider "aws" {
    alias = "prod"
    region = "us-east-1"  ##it will be first account so 
    profile = "anji(prod)"
}

provider "aws" {
    alias = "dev"  ##you need to give this compulsory with this it cant work 
    region = ap-south-1
    profile = sampi(dev)
}    

resource "aws_instance" "ec2_main" {
  provider        = aws.prod 
  ami             = var.ami_apsoutheast
  instance_type   = "t2.micro"
  key_name        = "linux-sea-key"
  security_groups = ["ansible-sg"]
  tags = {
    Name    = "account-main",
    Project = "multiprovider",
    Region  = "ap-southeast-1"
  }
}
resource "aws_instance" "ec2_dev" {
  provider        = aws.dev
  ami             = var.ami_useast
  instance_type   = "t2.micro"
  key_name        = "linux-useast-key"
  security_groups = ["ansible-sg"]
  tags = {
    Name    = "account-dev",
    Project = "multiprovider",
    Region  = "ap-southeast-1"
  }
}

variable "ami_apsoutheast" {
  type    = string
  default = "ami-0af2f764c580cc1f9"
}

variable "ami_useast" {
  type    = string
  default = "ami-00c39f71452c08778"
}
resource "aws_s3_bucket" {
    provider = aws.prod 
    bucket = "anji159258"
    acl    =  "public-read"
    lifecycle {
        prevent_destroy = true 
    }  

}  ##this is anji account automatically taken 

resource "aws_s3_bucket" {
    provider = aws.dev 
    bucket = "anji1592589"
    acl    =  "public-read"
    lifecycle {
        prevent_destroy = true 
    }  

}  

94-your using modules you need to print the public ip address of all the instances 

#it will print the ip address of all inside ec2 module 
output "publicip" {
  value = module.ec2
}

95-what is terraform locals 

>>In Terraform, locals are used to declare variables that are used within a module to simplify expressions or reuse values. Locals are evaluated during the Terraform graph building phase and can be useful for
making configurations more readable and maintainable. Here's a simple example of using locals in a Terraform configuration.
>>you can store localy that refer anywhere fro example public_ip printed 10 places rather than you can store in local call that using output 

# main.tf

provider "aws" {
  region = "us-east-1"
}

locals {
  resource_prefix = "myapp"
}

resource "aws_s3_bucket" "example_bucket" {
  bucket = "${local.resource_prefix}-s3-bucket"
  acl    = "private"
}

resource "aws_dynamodb_table" "example_table" {
  name           = "${local.resource_prefix}_dynamodb_table"
  read_capacity  = 5
  write_capacity = 5
  hash_key       = "id"
  attribute {
    name = "id"
    type = "N"
  }
}

96-can i use inside the aws_instance provision and outside also example 

resource "aws_instance" "web" {
    ami                   = "xxxxxxxxxxxxxxxxxxxxxx"
    instance_type         = "t2.micro"
    #it will create the 2 instance 
    count                 = 2
    ##it will create two instances based on the components you mentiod if write frontend in components it will create three   
    #first way these see below varaibles
    count                 = lenth(var.components) ## 

    tags = {
        #it will give the name one instance name is cart another instance name is catalogue  
        Name = var.components[count.index]
    }


  provisioner "remote-execc" {
    connection {
      host        = self.public_ip
      type        = "ssh"
      user        = ec2-user  
      private_key = "${file("test.pem")}" 
    }

    inline = [
      "false"
    ]
  }
}    

#outside youcan use null resource outsie of the instance

resource "aws_instance" "web" {
    ami                   = "xxxxxxxxxxxxxxxxxxxxxx"
    instance_type         = "t2.micro"
    #it will create the 2 instance 
    count                 = 2
    ##it will create two instances based on the components you mentiod if write frontend in components it will create three   
    #first way these see below varaibles
    count                 = lenth(var.components) ## 

    tags = {
        #it will give the name one instance name is cart another instance name is catalogue  
        Name = var.components[count.index]
    }
}

resource "null_resource" "execute" {
depends_on = [aws_instance.public-instances]
    connection {
        type = "ssh"
        host = aws_instance.web[1].public_ip  ##it will connect the first system only 
        user = "ubuntu"
        private_key = "${file("test.pem")}"
    }
    provisioner "file" {
    source      = "anji.sh"
    destination = "/tmp/anji.sh"
  }
}

97-your created 6 subnets but you want choose only one subnet for ec2 instance

>>using like this 
subnet_id  = aws_subnet.main.*.id[0] #this will select the first subnet 

98-how you can configure lookup in terraform 

vpc = {
  main = {
    cidr_block        = "10.0.0.0/16"
    availability_zone = ["us-east-1a", "us-east-1b"]
    public_subnets = {
      public = {
        name        = "public"
        cidr_block  = ["10.0.0.0/24", "10.0.1.0/24"]
        internet_gw = true
      }
    }
    private_subnets = {
      web = {
        name       = "web"
        cidr_block = ["10.0.2.0/24", "10.0.3.0/24"]
        nat_gw     = true
      }
      app = {
        name       = "app"
        cidr_block = ["10.0.4.0/24", "10.0.5.0/24"]
        nat_gw     = true
      }
      db = {
        name       = "db"
        cidr_block = ["10.0.6.0/24", "10.0.7.0/24"]
        nat_gw     = true
      }
    }

docdb = {
  main = {
    vpc_name            = "main"
    subnets_name        = "db"
    engine_version      = "4.0.0"
    number_of_instances = 1
    instance_class      = "db.t3.medium"
  }
}


module "docdb" {
  source = "github.com/raghudevopsb70/tf-module-docdb"
  env    = var.env

  for_each            = var.docdb
  subnet_ids          = lookup(lookup(lookup(lookup(module.vpc, each.value.vpc_name, null), "private_subnet_ids", null), each.value.subnets_name, null), "subnet_ids", null)
  vpc_id              = lookup(lookup(module.vpc, each.value.vpc_name, null), "vpc_id", null)
  allow_cidr          = lookup(lookup(lookup(lookup(var.vpc, each.value.vpc_name, null), "private_subnets", null), "app", null), "cidr_block", null)
  engine_version      = each.value.engine_version
  number_of_instances = each.value.number_of_instances
  instance_class      = each.value.instance_class
}
>>see the video of 52 and time 52mins  

99-what is try in terrafrom 

>>see video 60 15 mins  

100-if you use this like this count = var.listerner == ? 1 : 0

1->true
0->false   -->its basically true or false only if 1 means that condition execute if 0 menas that condition will not execute 

101-how you can install node exporter in any server is created using auto-scaling while using terafrom 

resource "aws_launch_configuration" "example" {
  name = "example_config"

  image_id = "ami-12345678"  # Replace with your AMI ID
  instance_type = "t2.micro" # Replace with your instance type

  lifecycle {
    create_before_destroy = true
  }

  user_data = <<-EOF
              #!/bin/bash
              curl -LO https://example.com/install_node_exporter.sh
              chmod +x install_node_exporter.sh
              ./install_node_exporter.sh
              EOF

  lifecycle {
    create_before_destroy = true
  }
}

resource "aws_autoscaling_group" "example" {
  desired_capacity     = 2
  max_size             = 4
  min_size             = 2
  launch_configuration = aws_launch_configuration.example.id

  # Rest of your autoscaling configuration...
}

vi install_node_exporter.sh

#!/bin/bash

# Node Exporter version to install (update accordingly)
NODE_EXPORTER_VERSION="1.2.3"

# Download and install Node Exporter
curl -LO "https://github.com/prometheus/node_exporter/releases/download/v${NODE_EXPORTER_VERSION}/node_exporter-${NODE_EXPORTER_VERSION}.linux-amd64.tar.gz"
tar -xvf "node_exporter-${NODE_EXPORTER_VERSION}.linux-amd64.tar.gz"
sudo mv "node_exporter-${NODE_EXPORTER_VERSION}.linux-amd64/node_exporter" /usr/local/bin/

# Create a non-privileged user for Node Exporter
sudo useradd -rs /bin/false node_exporter

# Create a systemd service for Node Exporter
sudo tee /etc/systemd/system/node_exporter.service > /dev/null <<EOF
[Unit]
Description=Node Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=node_exporter
ExecStart=/usr/local/bin/node_exporter

[Install]
WantedBy=default.target
EOF

# Reload systemd and start Node Exporter
sudo systemctl daemon-reload
sudo systemctl enable node_exporter
sudo systemctl start node_exporter

:wq

102-what is tfswitch 

>>tfswitch is a command-line tool that allows you to switch between different versions of Terraform seamlessly. It simplifies managing multiple Terraform versions on your system and ensures that you can easily
switch between them based on your project requirements.
>>For example, if you have projects that require Terraform version 0.14 and others that require version 0.15, TFSwitch enables you to switch between these versions effortlessly. By using TFSwitch, 
you can ensure that you're using the correct Terraform version for each project without the need to uninstall or reinstall different versions manually.
# Install tfswitch
brew install warrensbox/tap/tfswitch

# List available Terraform versions
tfswitch --list

# Switch to a specific version (e.g., 0.14.0)
tfswitch 0.14.0

# Check the currently active Terraform version
terraform version

# Run Terraform commands
terraform init
terraform plan
terraform apply

103-what happen if my terraform statefile deleted how to terminate the instance without going to the aws console

>>If your Terraform state file is deleted, it becomes challenging to manage your AWS resources using Terraform because Terraform relies on the state file to understand the current state of your infrastructure.
However, you can still manually terminate the instances in your AWS account without using the AWS Management Console by following these steps:

aws ec2 describe-instances
aws ec2 terminate-instances --instance-ids <instance-id>
aws ec2 delete-security-group --group-id <security-group-id>

104-types of variables in terraform

1-string
2-number
3-bool
4-list
5-set
6-map

105-if you lost statefile how we can achive this or recovery this 

>>if you lost the statefile you need to go what are the resource you have created then import command using then import it will create the statefile like what resource you created 
>>so its headache task instead you can use version control then you can recovery 
>>when you used backend statefile s3 bucket your executinng terraform using that file it will lock until your script complete and it wont allow the parallel execution
>>when you created the statefile using s3 and you given terraform code to another one he can terraform init then using that backend file then he can write new code or any changes do in previous code also work 

