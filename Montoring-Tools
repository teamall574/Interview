1-what is Montoring 

>>Collecting, processing, aggregating, and displaying real-time quantitative data about a system, such as query counts and types, error counts and types, processing times, and server lifetimes.
>>The Periodic tracking (for example, daily, weekly, monthly, quarterly, annually) of any activity's progress by systematically gathering and analyzing data and 
information is called Monitoring. like RAM , CPU , Memory , Network satistics or alerts 
>>monitoring on other hand to report or see the overall helath of the system

Why Montoring:-
1-Analyzing long-term trends:-How big is my database and how fast is it growing? How quickly is my daily-active user count growing?
2-Comparing over time and help you to design/tune the system. helps you to rightsize the infra   
3-Alerting
4-project dashboards
5-Retrospective Analysis 
6-what is broken and when and why broken 

2-types of montoring 

1-white box montoring:-Monitoring based on metrics exposed by the internals of the system, including logs, interfaces like the Java Virtual Machine Profiling Interface, or an HTTP handler that emits internal statistics.
>>white box monitoring is the monitoring of application running on the server. monitoring based on exposed by the internals of the system including logs interface
http handler that emits internal statists
2-Block box>>most of the people will focus on black box monitor.block box monitoring refers to the monitoring of server with a focus an area like disk space, memeory usage, 
load average, cpu utilization etc
>>Testing externally visible behavior as a user would see it.

3-what are the four golden things to monitor 

1-Latency:-The time it takes to service a request. It’s important to distinguish between the latency of successful requests and the latency of failed requests. For example, an HTTP 500 error triggered due to loss of connection to a database or other critical backend might be served very quickly; however, as an HTTP 500 error indicates a failed request, factoring 500s into your overall latency might result in misleading calculations. On the other hand, a slow error is even worse than a fast error! Therefore, it’s important to track error latency, as opposed to just filtering out errors 
2-Traffic:-A measure of how much demand is being placed on your system, measured in a high-level system-specific metric. For a web service, this measurement is usually HTTP requests per second, perhaps broken out by the nature of the requests (e.g., static versus dynamic content). For an audio streaming system, this measurement might focus on network I/O rate or concurrent sessions. For a key-value storage system, this measurement might be transactions and retrievals per second.
3-Errors:-The rate of requests that fail, either explicitly (e.g., HTTP 500s), implicitly (for example, an HTTP 200 success response, but coupled with the wrong content), or by policy (for example, "If you committed to one-second response times, any request over one second is an error"). Where protocol response codes are insufficient to express all failure conditions, secondary (internal) protocols may be necessary to track partial failure modes. Monitoring these cases can be drastically different: catching HTTP 500s at your load balancer can do a decent job of catching all completely failed requests, while only end-to-end system tests can detect that you’re serving the wrong content
4-Saturation:-How "full" your service is. A measure of your system fraction, emphasizing the resources that are most constrained (e.g., in a memory-constrained system, show memory; in an I/O-constrained system, show I/O). Note that many systems degrade in performance before they achieve 100% utilization, so having a utilization target is essential.
In complex systems, saturation can be supplemented with higher-level load measurement: can your service properly handle double the traffic, handle only 10% more traffic, or handle even less traffic than it currently receives? For very simple services that have no parameters that alter the complexity of the request (e.g., "Give me a nonce" or "I need a globally unique monotonic integer") that rarely change configuration, a static value from a load test might be adequate. As discussed in the previous paragraph, however, most services need to use indirect signals like CPU utilization or network bandwidth that have a known upper bound. Latency increases are often a leading indicator of saturation. Measuring your 99th percentile response time over some small window (e.g., one minute) can give a very early signal of saturation.
Finally, saturation is also concerned with predictions of impending saturation, such as "It looks like your database will fill its hard drive in 4 hours."

4-What is Prometheus

>>prometheus is a time series database. prometheus is designed to monitor targets servers,databases, standlone virtual machines pretty much everything can be 
monitored with prometheus
>>Prometheus is an open-source linux server montoring tool mainly used for metrics montoring, event montoring, alert montoring etc
>>prometheus uses for own powerful lanaguage "promQL"
>>promotheus uses multiple modes used for graphing and dashboarding support
>>you can create the custom roles and add in prometheus rules you can see in the prometheus this will help you to end complex commands
like what the amount free size memoty and data and cpu utilization
>>like wise you can add the alrets rules also

ex:-
groups:
  - name: custom_rules
    rules:
      - record: node_memory_MemFree_percent
        export: 100*-(100 * node_memory_Memfree_bytes / node_memory_MemTotal_bytes
      - record: node_filesystems_free_percents
        export:
 >>systemctl deamon-reload   -->it wil restart the deamon-sets
        
 record name will take the prometheus site or gui interface it will show the command output like how much free space or cpu utilization accroding to command

5-what is alert in Promethus

>>Alert is used to send notifications to the users or specified persons you can configure if the server fails then you cna send the notifications to user 

6-what is prometheus metrics endpoint

>>Prometheus is a monitoring platform that collects metrics from monitored targets by scraping metrics HTTP endpoints on these targets.

7-what is node exporter

>>node exportes is one of the prometheus exporters which is used to expose servers or systems OS Metrics
>>node exporter helps you to various resources of the system like RAM,CPU Utilzation, Memory Utilization, Disk Space

8-what is Alert manger

>>whenever alerts gone trigger the prometheus should inform to alert manager alert manager will send messages to users
>>The Alertmanager handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing them to the 
correct receiver integration such as email, PagerDuty, or OpsGenie. It also takes care of silencing and inhibition of alerts

9-what is observability

>>Observability means assembling all fragments from logs, monitoring tools and organize them in such a way which gives actionable knowledge of the whole environment 
thus creating an insight

Observability=Logging+Montoring+Visualization+Tracing
tools:-
1-dataddog
2-new-relic
3-splunk
4-elastic
5-grafana

10-what is the difference between montoring and observability

>>Monitoring tells you whether a system is working or not
>>Observability lets you ask why its not working

11-what is telemetry

>>Telemetry automatically collects, transmits and measures data from remote sources, using sensors and other devices to collect data. It uses communication systems to transmit the data back to a central location. Subsequently, the data is analyzed to monitor and control the remote system.
>>tel menas remote
>>metron means measure

telmetry data types
1-metrics (cpu and ram)
2-events (system evnets ,application evenets)
3-logs (system logs or network logs or anything)
4-traces (request)
this four types is called MELT

12-what is grafana

>>grafana is a multi-platform open-source analytics and interactive visualization tool it provides charts graph and alert when connected to supported data sources.
it is expandable through a plug-in system

>>dashboard number 14513 is linux
>>dasboard number  14510 is winodws
>>dashboard number 11802 is kubernetes
>>dashboard number 12268 is nginx logs and GEO map dashboard 
>>dashboard number 9614-nginx-ingress-controller
<<dashboard number 1860-node-exporter-full
>>dashboard number 8670-cluster-cost-utilization-metrics
>>dashboard number 13838-kubernetes-overview
>>dashboard number 8588-1-kubernetes-deployment-statefulset-daemonset-metrics
>>dashboard number 4358-elasticsearch
>>dashboard number 139-aws-billing
>>dashboard number 3119 kubernets 
>>dashboard number 10856 kubernets 
>>dashboard number 8685 kubernets 
>>dashboard number 315 kubernets 

1860
405
11074

13-Is it possible to change the port number 

Yes its possible /etc/garafana/grafana.ini

14-What databases work with Grafana?

>>by default grafana installs with sqlite is an embedded database stored in the grafana installtion location 
Grafana was first launched in 2014 and can now connect to a variety of data sources such as MySQL, SQL Server, Graphite, Prometheus, and others. 
This tool is most commonly used to build a time-series data visualization, which illustrates the health or utilization of a resource over time.

15-Is it possible to change grafana database sqlite to mysql 

>>yes its possible it will supports only in this databases postgress or sqlite or mysql 

16-what is grafana latest version

>>9.4.3

17-if we changing one version to another version what should you do 

>>you sholud take the backup of your database in grafana server using mysqldump or dump commands using 

18-What are the features provided by Grafana?

Visualization – Grafana helps us in viewing and understanding our data easily.
Alerting – Grafana is used in supporting numerous number of notification channels such as Slack, Pagerduty, etc.
Annotations – Grafana is used in helping us in annotate or in leaving notes on graphs.
Open Source – Grafana is used in backing an active vibrant community.

19-Is this possible to create the Report in grafana

>>Yes is possible to create the reports in Grafana using OpenNMS Dashboard

20-What is Grafana Cloud?

>>Grafana Cloud is used in observing platform, integrating metrics, tracing and logging with the help of Grafana.It is the best open source observability 
software that consists of Prometheus, Loki and Tempo without installing, maintaining and in scaling our observability stack.

21-What are Grafana Alerts?

>>Grafana Alerts helps in allows in attching rules in our dashboard panels, we can save the dashboard as it extracts the alert rules in a separate alert rule 
storage and schedules it for the evaluation.

Dashboard Alerts consists of 4 components as follows:

Alerting Rule used in creating an alert.
Contact Point used in sending notification when conditions of alerts rule are met.
Notification Policy used in grouping, matching and determining where, how to send notifications.
Silences used in matching and silencing notifications.

22-What are Cloud Logs?

Cloud Loggings helps in storing, searching, analyzing, monitoring and alerting on logging data and events from AWS Web Service and Google Cloud.

23-What is Grafana Dashboard Templates?

>>Grafana Dashboard Templates are used in making our dashboards interactive, we can create dashboard template variables which can be used anywhere in the 
Grafana Dashboard.These variables helps in allowing us in making dynamic changes to the dashboard.

24-What are Cloud Metrics?

>>Cloud Metrics helps in providing insights in our Cloud Computing and also predictive analysis of our system, and in determining when our servers are under load 
and requires provisioning.Cloud Metrics are also used in setting up thresholds through policies which will react in conditions during the cloud operations.
It also allows the cloud in self healing with auto fixing in the event of any operational failures

25-How do you check if the Grafana service is running or not?

You can validate that Grafana is running by checking the service’s status command as given below:

$ sudo systemctl status grafana-server

26-How to configure Grafana, so that dashboards can be viewed without requiring a password?

Make the following small configuration modifications to the default.ini/grafana.ini file to enable anonymous login (Grafana\conf).

27-What Is Graphite Grafana?

Graphite is a monitoring tool yet again. It makes time series data storage and viewing easier. In a data monitoring setup, Graphite is best used as a data source
for Grafana dashboard.
Grafana provides an advanced Graphite query editor that allows us to interact with data using expressions and functions.

28-What is Loki Grafana?

Loki is a Prometheus-inspired horizontally scalable, highly available, multi-tenant log aggregation system. It is intended to be both cost-effective and simple to use.
It uses a set of labels for each log stream rather than indexing the contents of the logs.

29- What Alert Notification Channels does Grafana Support?

Majorly it supports below Alert Notification Channels

Email
Slack
Kafka
Google Hangouts Chat
Microsoft Teams

30-What is difference between Grafana and Kibana?

>>Kibana’s main purpose was to analyze and monitor logs. In the ELK stack, K stands for Kibana. The ElasticSearch team developed Kibana with the goal of 
having a useful tool for monitoring logs. Instead of running Linux commands on the console to identify exceptions in production, simply navigate around and
track the context from the Kibana.

>>Grafana, on the other hand, is developed as a generic monitoring solution that can be used to monitor and analyze pretty much anything. 
This is a very high-level overview of the differences between the two tools.

31-How do you backup Grafana dashboards?

In order to backup your Grafana dashboard you may wish to consider using an open-source tool such as the Grafana backup tool.

This tool uses a Python application to backup not only Grafana dashboards but also backups your settings, folder permissions and alert channel configurations. 
There is also the option to use a managed service such as the platform offered by Logit.io, which offers this service by default as part of our commitment to our users.

32-How do you send data to Grafana?

To forward data to Grafana from different data sources you will need to navigate to “Data Sources” from the configuration menu.

33-What is InfluxDB used for?

>>InfluxDB is a time-series database written in the Go programming language.
>>InfluxDB is used for both the storage and retrieval of time series data and is commonly used by those who wish to perform operations monitoring as well as logs 
and metrics analysis.

34-What can I monitor with Grafana?

Grafana supports graph, singlestat, table, heatmap, and freetext panels, as well as integration with official and community-built plugins (like world map or clock)
and apps that could be visualized, too.

35-What is the difference between Splunk and Grafana?

Grafana is your tool if you need a product only for data visualization without spending a fortune on it. … Splunk is your product if you need a more 
versatile solution that can ingest any kind of data or logs and give you the capabilities to query and search through the data quickly.

36-What are the disadvantages of Grafana?

Cons to Grafana include:

Limitations on dashboard organization and design. Visualization panels are limited to those made available by Grafana Labs and its community. …
No data collection and storage. …
Limited data type visualizations.

37-What is Grafana Enterprise?

>>Grafana Enterprise is a paid version of Grafana that offers capabilities not available in the free source version. Grafana Enterprise gives you access to 
enterprise plugins, which allow you to use your existing data sources in Grafana. This means you can get the most out of your complicated, 
costly monitoring solutions and databases by viewing all of the data in a more efficient and effective manner.

38-What is Grafana Loki and How does it work?

>>Grafana Loki is a log aggregation tool that collects and organizes logs from all of your apps and infrastructure. It offers a unique approach by 
indexing only the metadata of the log lines rather than the complete text

39-Why use Grafana Loki?

Because you may distribute logs in any format, from any source, and through a number of clients, getting started is simple.
With 100 per cent persistence to object storage, you get petabyte-scale, fast throughput, cost-effective & durable storage, and cost-effective & durable storage.
Your log lines can be used to create metrics and alarms.
Ingestion logs have no formatting requirements, providing you more flexibility and the ability to format at query time.
Follow your logs in real-time to see them as they arrive in the system, to have them updated after a set length of time, to see logs for a given day, and so on.
Prometheus, Grafana, and K8s all have native integrations, allowing you to seamlessly move between metrics, logs, and traces.

40-What are Grafana plugins?

1-panel plugins
2-data source plugins
3-app plugins

41-how to save logs in grafana to s3

>>it depends which S3 logging option 70 you choose. If you choose CloudTrail you could export the logs CloudWatch Logs 16 and then import them with our 
Lambda Promtail 136. However, if you choose to store the logs in an S3 bucket we would have to add a Promtail target for S3.

42-What is Graphite DB?

A: Graphite DB is an open-source time-series database. This means that it is able to store time-series data and render graphs based upon this data.

43-what is datadog

>>datadog is a montoring service tool for cloud-scale applications providing monitoring of servers databases tools and services through a SAAS based data analytics
platform
>>it is easy to use
>>providing functionalty
>>it will install an agent in all servers and get the metrics and cpu utilization and events and alrets and network
>>it will check the availbilty and performance and reliability of your application or servers
>>datadog uses go based agent 
>>it will support more than 400 + integartions

44-how to install Prometheus server with direct execution 

>>wget https://github.com/prometheus/prometheus/releases/download/v1.11.0/prometheus-1.11.0.linux-amd64.tar.gz
>>tar xvfz prometheus-1.11.0.linux-amd64.tar.gz
>>sudo mv prometheus-1.11.0.linux-amd64 /usr/local/prometheus
>>sudo ln -s /usr/local/prometheus/prometheus-1.11.0.linux-amd64 /usr/local/prometheus/current
>>vi /etc/systemd/system/prometheus.service
[Unit]
Description=Prometheus
Wants=network-online.target
After=network-online.target

[Service]
ExecStart=/usr/local/prometheus/current/prometheus --config.file=/usr/local/prometheus/current/prometheus.yml
ExecReload=/bin/kill -HUP $MAINPID
Restart=always

[Install]
WantedBy=default.target
>>:wq
>>sudo systemctl start prometheus
>>sudo systemctl enable prometheus

second-type:-

bash sudo vi /etc/yum.repos.d/prometheus.repo
[prometheus] 
name=Prometheus repository 
baseurl=https://packagecloud.io/prometheus-rpm/release/el/$releasever/$basearch 
gpgcheck=1 
enabled=1 
gpgkey=https://packagecloud.io/prometheus-rpm/release/gpgkey
sslverify=1
sslcacert=/etc/pki/tls/certs/ca-bundle.crt
:wq
bash sudo yum makecache
bash sudo yum install prometheus
bash sudo systemctl start prometheus
bash sudo systemctl enable prometheus

third-type:-

>>sudo useradd --no-create-home --shell /bin/false prometheus
>>wget https://github.com/prometheus/prometheus/releases/download/v2.42.0/prometheus-2.42.0.linux-amd64.tar.gz
>>sudo mkdir /etc/prometheus /var/lib/prometheus
>>sudo chown prometheus:prometheus /etc/prometheus /var/lib/prometheus
>>tar -xvzf prometheus-2.42.0.linux-amd64.tar.gz
>>mv prometheus-2.42.0.linux-amd64.tar.gz prometheus

Copy “prometheus” and “promtool” binary and change ownership
>>cp prometheuspackage/prometheus /usr/local/bin/
>>cp prometheuspackage/promtool /usr/local/bin/
>>chown prometheus:prometheus /usr/local/bin/prometheus
>>chown prometheus:prometheus /usr/local/bin/promtool
Copy “consoles” and “console_libraries”
>>cp -r prometheuspackage/consoles /etc/prometheus
>>cp -r prometheuspackage/console_libraries /etc/prometheus
>>chown -R prometheus:prometheus /etc/prometheus/consoles
>>chown -R prometheus:prometheus /etc/prometheus/console_libraries
Configure Prmetheus
vi /etc/prometheus/prometheus.yml

global:
  scrape_interval: 10s

scrape_configs:
  - job_name: 'prometheus_master'
    scrape_interval: 5s
    static_configs:
      - targets: ['SERVER_IP:9090']
:wq

Change the ownership
>>chown prometheus:prometheus /etc/prometheus/prometheus.yml

vi /etc/systemd/system/prometheus.service

[Unit]
Description=Prometheus
Wants=network-online.target
After=network-online.target
[Service]
User=prometheus
Group=prometheus
Type=simple
ExecStart=/usr/local/bin/prometheus \
--config.file /etc/prometheus/prometheus.yml \
--storage.tsdb.path /var/lib/prometheus/ \
--web.console.templates=/etc/prometheus/consoles \
--web.console.libraries=/etc/prometheus/console_libraries
[Install]
WantedBy=multi-user.target

#start service
systemctl daemon-reload
systemctl start prometheus
systemctl status prometheus

http://SERVER_IP:9090/graph

45-what is promethues querys 

>>node_cpu_seconds_total
>>absent()
>>http_requests_total
>>rate(http_requests_total[5m])[30m:1m]
>>http_requests_total{job=~".*server"}
>>http_requests_total{status!~"4.."}
>>rate(http_requests_total[5m])
>>count by (app) (instance_cpu_time_ns)
>>rate(node_cpu_seconds_total[1m]) * 100
>>celi(rate(node_cpu_seconds_total[1m]) * 100)  -->low 
>>floor(rate(node_cpu_seconds_total[1m]) * 100)  -->high 
>>floor(rate(node_cpu_seconds_total{ mode="idle" }[1m]) * 100)  -->it will show how many cpus you have 
>>avg by (name) (floor(rate(node_cpu_seconds_total{mode="idle"}[1m]) * 100))  -->it will give cpu free space 
celi(100- (100 * node_memory_MemAvailble_bytes / node_memory_MemAvailble_bytes) )  -->it will show the 100 to how much used  

46-when you using ec2_sd-config you want see the system name or labels or tags how you will achive this in Prometheus

>>see videos 61 1:12 mins 
>>you cna achive this using relabel_configs using this will go check you ec2 instance tags it will give you using this snippet

- job name: 'nodes'
  ec2_sd_configs:
    - region: us-east-1
      access_key:
      secret_key:
      port: 9100 
  relabel_configs:
  - source_labels: [_meta_ec2_tag_env]
    target_label: environment  #it will give what label you given this will show that  
  - source_labels: [_meta_ec2_tag_env]
    target_label: name   ##it will giev system name what you created like ex: cart system or frontend System 
>>if you want you filter some servers dont to show this in prometheus  some of the servers dont want montior are any other servers 
  filter:
    name: "tag:project"
    value: ["devlopment-servers"]  

47-what is service discovery in Prometheus

>>In Prometheus, service discovery refers to the automated process of finding and scraping metrics from target hosts that expose Prometheus-compatible endpoints. This eliminates the need to manually 
configure static lists of targets, making your monitoring setup more dynamic and easier to manage.
>>ec2_sd_config automatically monitor you need to give the snippet in Prometheus.yaml file under targets 

- job name: 'nodes'
  ec2_sd_configs:
    - region: us-east-1
      access_key:
      secret_key:
      port: 9100 

this will any node created under us-east-1 automcatically see the nodes you need install the node exporter in all the machines use any script and dont give access key and secret key insted you assign the role
with ec2-read-only-access is enough attach that role Prometheus server    

48-what does prometheus do

>>Prometheus metrics from clients in frequent amount of time as defined scrape config 
>>here client just offers the dataover API Prometheus just collects them 
>>pull can be made by multiple servers 

49-what Prometheus does not do 

>>Raw log and event log is not stored instead you can splunk & elk 
>>Tracing data sampling (instana & jaeger)
>>does not do MachineLearning & Detection 
>>long term stoarge , max of 15 days (use this victoriametrics, thanos )
>>does not support scaling 
>>does not have auth mechanismseither for users or even for nodes also 

50-what Prometheus does 

1-metrics collection and store in time series database 
2-Querying :-enquirying the details  
3-Alerting 
4-Graphing / Trends 

51-
