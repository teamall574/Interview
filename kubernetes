
13-how to see the how much cpu and memory using the pod 

>>kubectl top pods   -->it will show the pods details only
>>kubecctl top nodes    -->it will show nodes cpu and memory also


201-what is Telemetery

>>Telemetery is fancy word it is used to gathering the metrics 

207-what is HA-Proxy what is exactly ha-proxy will do what is HA-Proxy 

>>HAProxy, which stands for High Availability Proxy, is an open-source software solution that provides high availability, load balancing, and proxying for TCP and HTTP-based applications. 
It is widely used to ensure the availability, scalability, and reliability of web services and applications.
Here's what HAProxy does
1-Load Balancing:
2-High Availability
3-Proxying
4-Health Checks
5-Layer 4 and Layer 7 Load Balancing
6-SSL/TLS Offloading
7-Content Switching
8-Session Persistence
9-Rate Limiting
10-Logging and Monitoring:

208-which algorithm used in ha-proxy

>>HAProxy uses several load-balancing algorithms to distribute traffic among backend servers. The choice of algorithm can significantly impact the performance and behavior of the load balancer.
HAProxy offers the following load-balancing algorithms
1-Round Robin (default):
2-Least Connections:
3-Source IP Hash:
4-URI Hash:
5-URL Parameter Hash:
6-Static-RR (Static Round Robin):
7-Least Response Time
8-Random:

209-in this which one is better 

>>it is dependencies up on the server utilization like memory ram cpu and static content like mostly round robin uses if you have 10 servers same configuartion 8gb memory example round robin
one of my vitual machine good capacity we can create weight sticy to that server sticky alogorithum 

210-what is name space in kubernetes

>>it is like divideing into one cluster to many cluster to isloate the workspace 
>>like we can create the for security namespace and database divide or isolate 

201-how to send the traffic pod-A to pod-B 

>>uisng drain or active command uisng or cordon or uncordon 

185-what is the meaning of beta and stable

>>beta means testing
>>stable means release

186-what is Envoy proxy

>>ENVOY is and opensource edge and service proxy designed for cloud native applications 
>>Envoy proxy is a high-performance proxy developed in C++ to mediate all inbound and outbound traffic for all servicesin the service mesh. envoy proxies are the only Istion complements that are interact 
with data plane traffic   
features of ENVOY:-
1-Traffic control 
-A different load-balancing policy to traffic for partcular subset of service instances
-Stageed rollouts with % based traffic split 
-HTTP/2 and GRPC proxies 
-IStio Resources
>>virtual service 
>>Destination rules
>>Gateways
>>Service entries
>>Sidecars 

2-Network Resilency
-Fault Injection
-Retries
-circuit breakers
-Failovers
-Health checks 

3-Security and Authentication
-Rate-limiting  
-TLS Termination

187-why not use envoy instead of Istio

>>Envoy and Istio serve complementary but different purposes in the world of microservices and service mesh architectures. Envoy is a high-performance proxy designed for network communication and is often
used as the data plane component within service mesh architectures. Istio, on the other hand, is a comprehensive service mesh platform that includes Envoy proxies but also offers a control plane for 
managing and securing microservices.
>>Envoy proxy is capable of being deployed into many different types of clusters that means it has a massive and complex terminology of its own  

Reasons:-
1-Higher-Level Abstractions:-Istio provides a layer of higher-level abstractions, making it easier to manage and secure microservices. It includes features like traffic management, load balancing, security, 
telemetry, and policy enforcement, all managed through a central control plane. This simplifies the configuration and management of complex microservices environments.
2-Security and Observability:-Istio offers robust security features, such as mutual TLS (mTLS) authentication, rate limiting, and access control policies. It also integrates with various observability tools,
including Prometheus and Grafana, to provide insights into service behavior.
3-Consistent and Secure Traffic Management:-Istio abstracts the complexities of traffic management. You can define routing rules, canary deployments, and retries using Istio's high-level configuration 
rather than configuring individual proxies manually. It provides a consistent way to manage traffic across multiple services
4-Multi-Cluster and Multi-Cloud Support:-Istio is designed to work across multiple clusters and cloud environments, providing a consistent way to manage services, regardless of where they are hosted. 
It can be a valuable tool for organizations with hybrid or multi-cloud deployments.
5-Service Mesh Ecosystem:-Istio has a growing ecosystem of plugins, extensions, and integrations that build upon its functionality. This includes tools for canary releases, fault injection, chaos testing,
and more.
6-End-User and Developer Friendliness:-Istio's higher-level abstractions make it more user-friendly for developers and operators. It provides a simpler interface for configuring and managing traffic, security,
and observability without requiring in-depth knowledge of Envoy proxy configuration.
7-Community and Support:-Istio has a vibrant open-source community and is backed by major organizations, including Google, IBM, and Red Hat. This provides a level of support and development resources that 
may be challenging to replicate when using Envoy directly.

188-what is the difference between virtual service and gateway in istio

In Istio, both VirtualServices and Gateways are important resources used for managing and controlling traffic within a service mesh, but they serve different purposes. Here's a breakdown of the differences 
between VirtualServices and Gateways:

VirtualService:
>>Purpose: Virtual services are primarily used for controlling the routing and traffic behavior within the service mesh. They define how incoming requests to a specific host should be routed to different
services or subsets, and they specify rules for handling those requests.
>>Host Matching: Virtual Services are often used for specifying rules based on the host or URL path. You can define different routing behaviors for requests to different hosts or paths, making them ideal for
service-to-service communication within the mesh.
Layer 7 (Application Layer) Routing:VirtualServices are more focused on Layer 7 (application layer) routing. They can be used to implement features like request rewriting, request/response timeouts, retries, 
and load balancing strategies. They work with HTTP, gRPC, and other application-layer protocols.
Service Discovery:VirtualServices rely on the service discovery mechanisms within Istio to route traffic to services registered in the service mesh. They allow you to specify routing based on service names 
and labels.
Internal Routing:VirtualServices are often used for routing traffic between services within the service mesh, controlling how traffic flows between different services, versions, or subsets.
Gateway:
Purpose:Gateways are used to manage and control the entry and exit points of traffic into and out of the service mesh. They define how traffic from outside the mesh should be routed to services within the 
mesh or vice versa. Gateways are the entry points for external traffic.
Host Matching:Gateways are used to specify rules based on hosts, but their primary purpose is to route incoming traffic from the internet or other external sources to services within the mesh.
Layer 4 (Transport Layer) Routing:Gateways are more focused on Layer 4 (transport layer) routing. They can be used to route traffic based on ports and protocols, making them suitable for handling raw
TCP or UDP traffic in addition to HTTP and HTTPS.
External Traffic:Gateways handle traffic that originates from outside the service mesh. They are typically associated with a public IP address or a domain name and are responsible for forwarding external 
traffic to services within the mesh.
Ingress and Egress:Gateways are commonly used for configuring ingress (incoming traffic from external sources) and egress (outgoing traffic to external destinations) traffic control. 
They allow you to manage how external clients access services inside the mesh and how services in the mesh access external resources.

189-what is service entry in Istio

>>In Istio, a service entry is a configuration object that defines how traffic should be routed to services outside of the mesh. It allows Istio to manage traffic to and from services that are not part of
the Kubernetes cluster or services that are running on different clusters.

apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: external-svc
spec:
  hosts:
  - external-service.com
  ports:
  - number: 80
    name: http
    protocol: HTTP
  location: MESH_EXTERNAL
  resolution: DNS

190-what is destinationRule in Istio

>>In Istio, a DestinationRule is a resource that allows you to configure policies for the traffic of a service, specifically how the traffic is handled at the destination (service) level. 
DestinationRule defines rules and settings for how Istio should manage connections to a particular service version.

apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: my-destination-rule
spec:
  host: my-service
  subsets:
  - name: v1
    labels:
      version: "v1"
  - name: v2
    labels:
      version: "v2"
  trafficPolicy:
    loadBalancer:
      simple: RANDOM

191-what are the traffic managements or networking paths in Istio

1-Destination rules :-you can use load-balancer like roundrobin or simple 
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: bookinfo-ratings-port
spec:
  host: ratings.prod.svc.cluster.local
  trafficPolicy: # Apply to all ports
    portLevelSettings:
    - port:
        number: 80
      loadBalancer:
        simple: LEAST_REQUEST
    - port:
        number: 9080
      loadBalancer:
        simple: ROUND_ROBIN

2-ProxyConfig
3-VirtualService:-
4-Workload entry
5-Service Entry 
6-Envoy filter
7-Gateway
8-sidecar
9-Workload group

192-


171-How ingress helps in Kubernetes?

1-Routing
2-Load balancing
3-Access control
4-TLS Termination

172-what layer will be used in ingress kubernetes

>>Ingress controllers support routing through both the transport layer (OSI – Layer 4) and the application layer (OSI – Layer 7)

173-is this podssible to create one ingree controller inside one more ingress

>>Ans: yes

174-what needs to create an ingress

1-namespace
2-serviceAccount
3-configmap
4-clusterrole
5-clusterrolebinding
6-role
7-rolebinding
8-service
9-service(twotimes)
10-deployment
11-ValidatingWebhookConfiguration

175-how would you create the DNS in Kubernetes in private using

>> Using ingress you can create the DNS locally using you can apply these domains using Route53 to make it public

176-what is Governance in kubernetes

>>managing according to the compilance of orgnazation.compilance is nothing but roles
for example no should create 64gb memory more tahn system or no can use the latest tag to create pods in kubernetes
>>using kyverno tool to governance you do adminssion controller. it will validate and mutate the authenticated and authorized user request
>>for example your using kyverno you implemented some resource quota some will come and deploy the pods and deployments it will restrict the creation of pods without using resource quota
kyverno will restrict the pods without using or mention without resourcce quota

177-what is kyverno in kubernetes

>>Kyverno is a policy engine designed for Kubernetes
>>Kyverno is a policy engine designed for Kubernetes
>>A Kyverno policy is a collection of rules. Each rule consists of a match declaration, an optional exclude declaration, and one of a validate, mutate, generate, or verifyImages declaration.
Each rule can contain only a single validate, mutate, generate, or verifyImages child declaration.Policies can be defined as cluster-wide resources (using the kind ClusterPolicy) or 
namespaced resources (using the kind Policy.) As expected, namespaced policies will only apply to resources within the namespace in which they are defined while cluster-wide policies are 
applied to matching resources across all namespaces. Otherwise, there is no difference between the two types.
>>This allows using familiar tools such as kubectl , git , and kustomize to manage policies. Kyverno policies can validate, mutate, generate, and cleanup Kubernetes resources, and verify
image signatures and artifacts to help secure the software supply chain.

kyverno will do this four important topics
1-Generate
2-validate
3-mutate
4-verfiy image

178-how to secure your kubernetes cluster

1-Secure API-Server:-
kubectl get pods | grep kube-api-server
add the tls and crt file this will help to secure your API-Server
2-RBAC:-Restrict the access to unauthorized the users using(Service-Accounts, Role, Cluster-Role)
3-Network-policies:-restrict the namespace using network policies
4-ETCD encryption:- Configure the key management system to store and manage encryption keys.
5-Secure container images:- scan docker images using this
docker sync --severity dockerhub.io/anji1592/test:latest
6-cluster montoring:- dont run your pod on root environment use sysdig to monirot your cluster actions
7-upgrades cluster:-Keep the Kubernetes cluster and its components up to date with the latest security patches and updates.

179-in kubernetes any user dont use latest tag to create the pod  ,deployment, replicasets, statefulsets  in kubernetes how we can achive this

>>To prevent users from using the "latest" tag for creating pods, deployments, replicasets, and statefulsets in Kubernetes, you can enforce image tag immutability by implementing a 
combination of custom Admission Controllers and Pod Security Policies (PSP). This approach will allow you to intercept and modify requests to the API server and enforce stricter policies
for image tags
Step 1: Create a Custom Admission Controller:
Step 2: Define Pod Security Policies: Pod Security Policies (PSP) in Kubernetes to enforce stricter security settings for Pod creation. PSP allows you to restrict the usage of certain 
image tags, among other security-related configurations.

apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: disallow-latest-tag
spec:
  privileged: false
  seLinux:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  runAsUser:
    rule: RunAsAny
  fsGroup:
    rule: RunAsAny
  volumes:
    - '*'
  hostNetwork: false
  hostIPC: false
  hostPID: false
  allowedCapabilities: []
  hostPorts: []
  allowedHostPaths: []
  allowedFlexVolumes: []
  forbiddenSysctls:
    - '*'
  readOnlyRootFilesystem: false
  defaultAddCapabilities: []
  requiredDropCapabilities: []
  allowedProcMountTypes: []
  allowedUnsafeSysctls: []
  allowedCSIDrivers: []
  allowedUnsafeSysctls: []
  allowedImageTags:
    - "*"
    - "!latest"  # Disallow usage of "latest" tag
>>kubectl apply -f path/to/pod-security-policy.yaml
Create a ClusterRole and ClusterRoleBinding to allow the admission controller to access the Pod Security Policy:
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: admission-controller-access
rules:
  - apiGroups: ["policy"]
    resources: ["podsecuritypolicies"]
    resourceNames: ["disallow-latest-tag"]
    verbs: ["use"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admission-controller-access
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: admission-controller-access
subjects:
  - apiGroup: ""
    kind: ServiceAccount
    name: admission-controller-service-account
    namespace: <NAMESPACE>  # Replace with the namespace where the admission controller runs
>>kubectl apply -f path/to/cluster-role.yaml

Step 3: Configure the Admission Controller:Register the webhook server (admission controller) as a ValidatingAdmissionWebhook for the Kubernetes API server. 
The admission controller will intercept and validate requests before they are admitted.

180-In my organization keep growing how to implement the restrications like user most use resource quota if he cant use he get an error how you will achive this

>>you can create the cutsom admission controllers or you can use kyverno then you can restrict pods without resource request and limit when user creating pods or deployments or replicasets 

apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: require-requests-limits
  annotations:
    policies.kyverno.io/title: Require Limits and Requests
    policies.kyverno.io/category: Best Practices, EKS Best Practices
    policies.kyverno.io/severity: medium
    policies.kyverno.io/subject: Pod
    policies.kyverno.io/minversion: 1.6.0
    policies.kyverno.io/description: >-
      As application workloads share cluster resources, it is important to limit resources
      requested and consumed by each Pod. It is recommended to require resource requests and
      limits per Pod, especially for memory and CPU. If a Namespace level request or limit is specified,
      defaults will automatically be applied to each Pod based on the LimitRange configuration.
      This policy validates that all containers have something specified for memory and CPU
      requests and memory limits.
spec:
  validationFailureAction: audit
  background: true
  rules:
  - name: validate-resources
    match:
      any:
      - resources:
          kinds:
          - Pod
          - Deployments
          - stateful sets like this mention
          - replicasets
    validate:
      message: "CPU and memory resource requests and limits are required."
      pattern:
        spec:
          containers:
          - resources:
              requests:
                memory: "?*"
                cpu: "?*"
              limits:
                memory: "?*"

181-what is K3S

>>K3s is a lightweight Kubernetes distribution created by Rancher Labs, and it is fully certified by the Cloud Native Computing Foundation (CNCF). 
K3s is highly available and production-ready. It has a very small binary size and very low resource requirements.

182-what is Rancher

>>Rancher is a Kubernetes management tool to deploy and run clusters anywhere and on any provider. Rancher can provision Kubernetes from a hosted provider, 
provision compute nodes and then install Kubernetes onto them, or import existing Kubernetes clusters running anywhere.

183-what is DevSecOps

>>DevSecOps is  it is invove in each stage in like security using SAST or DAST like manula or automatic
>>if you involve or implemented this in your pipeline we have several benfites like
1-Low-Cost
2-Low-Risk
3-production is fast
4-speed in the delivery

184-what is security aspects

>>Integrate security into every step of the SDLC ->software life cycle Development
1-static code Analysis
2-Dependency Scanning
3-Dynamic application testing
4-container scaling
5-continous compliance
6-Runtime security

1-Development code
>>we can create or add pre-commit hooks and pre-publish hooks when developer tries to push the code or commit the code it runs the test to check the any sensitive data is there
2-Git(Github-or-BitBucket-Gitlab)
>>we can configure to check the code scans or secret credentials scan any keys or passwords is exposing if it we can use the hashicorp or secret vaults will be used
3-Test 
>>In this stage we can run the unit test and mutation test we can use static code analysis using sonarqube or any other tools
4-Build 
>>we can create the package we can check the Dependency check and when we created the images we can check the docker images like images scan using trivy or any-other tools and also use image signature
5-Deploy-stage
>>when we deploying the stage we can run the validate image signature and integration testing
6-Deploy-production
>>In this stage we can run validate runtime configs and DAST pentesting and check the compilance checks and performance Test
7-Montior
>>In this stage we will check the log aggregation and check the security logs and resource utilization
8-Security 
>>In this stage we will check the SSL/TLS and Network Policies and Auditing the policies whether its correct or not 

185-what is the use of Jococo plugin

>>it is used to generate report of tests you can convert them into report also  
>>you can install this plugin in jenkins and add the pom.xml also using maven repository

186-what is Talisman

>>It will scan your repository it will check the pattern any sensitive info going to the github or not  
>>Talisman installs a hook to your repository to ensure that potential secrest or sensitive information donot leave the developers's workstation
>>it validates the outgoing change for things that look suspicious like potential SSH Keys, authorization tokens, private keys etc
you can install this in 2 ways
1-global installation
2-single project installation
this need to install developer machines when developer push the any secret sensitie information it gives the error push failed. you can ignore talisman by
creating .talismanrc  in this file add your deails it will ignore that file
  
187-what is CVE 

>>common vulnerability exposure

188-what is CVSS

>>common vulnerability scroing system

189-what is CWE 

>>common weakness enumeration

190-what is JAR or WAR

>>packaged application is called jar or war like source code + dependencies

191-what is OPA Confest

>>The Open Policy Agnet(OPA, pronounced "oh-pa") is an open source general-purpose policy engine that unifies policy enforcement across the stack 
>>It is used to improve the security
>>dont run docker images in root privileages its not a best practice and dont use latest tags in Docker images 
>>if your not used base images or using root directly it will scan the dockerfile and give error in your pipeline. if your unnecessarily use copy insteadd of add it will error fail the pipeline   
>>you can set this into kubernetes also for example we added the test dont run the root user created user in docker file you need to mention that deploymnet file in userid of user  

192-what is kubesec 

>>kubesec is an open-source kubernets security scanner and analysis tool. it scans your kubernetes cluster for command exploitable risk such as privileged capabilites and provides a severity score for 
each found vulnerability 

>>dast means we can test the application after runing sast means we can test the application line by line not a runned application
>>DAST hasno access to an application's source code it detects security vulnerabilitys y attacking the application externally 

193-what is CIS Benchmarks

>>The center for Internet Security(CIS) releases benchmarks for best practice security recommendations

194-what is kube bench 

>>using kube-bench you can scan the infrasture or compliance scan to check the kubernetes all the security aspects correct or not 

>>kubectl get crd   -->it will show the custom resource defination in kubernetes
>>kubectl get pa -A  -->it will show the peerauthentication in kubernetes 
>>kube-bench 
>>kube-bench node --check 4.2.1 --json | jq

195-what is MTLS

>>From this, MTLS or mutual Transport Layer Security has both parties authenticate via certificates to provide an additional security measure to cross network communication.

196-what is peer-authentication in Istio and types of modes  

>>peerauthentication is that you can enable or disable the mtls connection pod to pod connection or network by using peerauthentication
>>STRICT
>>DISABLE
>>PERMISSIVE

apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata: 
  name: default
  namespace: istio-system  ##if you give this namespace means all the namespace will infect it is global
spec:
  mtls:  ##by default automcatically came if you want disable you can create 
    mode: PERMISSIVE  #if your using permissive this any pod created in the istio-system the pod will go onto the mtls mutual-tls if you DISABLE it will go plan text 
          ##if you use the STRICT mode the communcation will stop why because the pod will not allow without tls certicates
          
>>kubectl get crd  -->it will show the peer authentication
>>kubectl edit pa -n istio-system  -->you can change the peer authentication or mtls 

197-what is the use case of kiali

>>it will show the beautiful dashboard and show how the network happens and shoing the peering authentication and gateways and virtual service and editble options also 
>>it will graph how the trafiic happines to where the traffic going using mtls or not  

198-what is CAdvisior

>>cAdvisor is an open-source agent integrated into the kubelet binary that monitors resource usage and analyzes the performance of containers. It collects statistics about the CPU, memory, file, 
and network usage for all containers running on a given node (it does not operate at the pod level)

199-what is Falco in kubernetes

>>Falco  detects unecpected application behavior and alerts on threat at runtime. It has complete container visibility through a single sensor that allows to gain insight into 
application and container behavior
>>for example falco will run it will track the shell like anyone login into pod then it will store the logs so if you configure any notification it will send the notification teams datadog slack 

200-what is kubescan

>>kubescan using you can see the risk factors of your name space along with grphical representation 

if it is a restful api then jar will create
if it is webapp then war file create 

201-what is kafka what is the advantages of kafka

>>Apache Kafka is a distributed data store optimized for ingesting and processing streaming data in real-time. Streaming data is data that is continuously generated by thousands of data sources, 
which typically send the data records in simultaneously.
>>it is availble in managed service in AWS name AmazonMSk 
>>kafka port number 9092
install kafka in local system then enter folder run this command 
>>bin/kafka-topics.sh --create --topic anji-1 --bootstrap-server kafaka-endpoint-here:9092

202-what is the jaegur

>>jaegur will do end-to-end tracing will show 

203-what probleams slove in kubernetes

>>self the helaing(kubernetes will montior and check helath for every pod)
>>Scalability: While Kubernetes is designed to handle large-scale deployments, scaling applications within a Kubernetes cluster can still be challenging
>>Networking: Networking in Kubernetes can be complex, especially when dealing with multiple pods, services, and load balancers. Configuring network policies, setting up service discovery, and handling 
ingress and egress traffic can pose challenges.
>>Monitoring and Logging: Kubernetes provides basic monitoring and logging capabilities, but setting up a comprehensive monitoring and logging stack can be complex
>>Persistent Storage: Managing persistent storage in Kubernetes can be challenging. Although Kubernetes provides mechanisms like Persistent Volumes (PVs) and Persistent Volume Claims (PVCs)

204-what is Yaml

>>yaml is humann readble language. this not markup lanaguage
>>it is serialization lanaguage:-when you sending data from soure to destination your using the network when you sending it will serialized when it goes internet it will be converted into byte stream and
the destination will be convert binay to Deserialization
>>serialization languages like xml yaml json

205-what is self healing in kubernetes

>>you have mention 3 replicas in a node if the pod is deleted then automatically create the pod

206-what is the high availbilty in kubernetes

>>if your using replicas 3 and suddenly the worker is noe is deleted or stopped then replicas will move into another node automatically

207-what is rollout and rollback

RollOut:-
>>A rolling deployment is a deployment strategy that slowly replaces previous versions of an application with new versions of an application by completely replacing the infrastructure on which the application
is running.
>>kubectl set image deployment/app-your image nginx-caontainer=nginx-1.23.new-image

>>kubectl rollout history deployment/nginx-deployment -->it will show the history of rollout

>>kubectl set image deployment/app-your image nginx-caontainer=nginx-1.23.new-image  --record   --->it will show the reocrd when you seee history

RollBack:-
>>rolls back deployments by redeploying a previously deployed revision of an application as a new deployment. These rolled-back deployments are technically new deployments, with new deployment IDs,
rather than restored versions of a previous deployment.

>>kubectl rollout undo deployment/nginx-deployment --to-revicion=1

208-what is the Best-Practices when you applying probes

1-ideal frequency
2-light-weight
3-correct Restart policy
4-use probe when only needed
5-keep an eyes on probes regularly

209-what is node selector

>>your created some labels in your nodes and then your specify the node selector you deploy your pods in specific node 

nodeSelector: 
        env: dev

210-how to connect the mongodb

>>you can use mongose to connect the mongodb 

211-how to see the container pids in kuberebtes

>>ps aux

212-what are sidecar containers

>> You can run multiple tasks and it will update the task in sidecar containers 
>> It is like syncing in your volume 
>> We can run the refresh part in separate containers without disturbing the main container this refresh service pulls the code or configuration from GitHub from every update or every second of the volume 
this is called a sidecar container 

213-what is the use of multiple containers in a single pod

>>need to run backend jobs(ex:-git sync run in background using emptydir)

214-what is BackoffLimitExceeded

>> When you mention BackoffLimitExceeded:3 means if the pod getting restarted 3 times it will stop and give an error it will not try every time restart again and again
>> It will control the load of your system If you do not specify it will run again & again which will consume more memory in your system
>> We also specify the active deadline seconds: 100 If it takes more than 100 seconds it will be marked as failed

215-what is job in kubenrets

>> It is used to run the job at one time you can specify but you can mention ttl second after finished: 60 if the job is completed then delete the job after 60 seconds 

216-what is cronjob in Kubernetes

>> It will run every second if you specify if not you can specify using the cronjob-specific time
>> You schedule jobs using cronjob it will run at that time
ex:- 
1-DB-Backup
2-Log-Rotation
3-Data-Processing

217-what problems will face if you install or using KOPS as production environment

>>if managed cluster went down not able to do any activity until it will come remains everything works file includes worker node and pods everything. if your using 3 master cluster then this 
will not face in production problem
>>if the certifactes may expiry
>>api server is down
>>etcd is crashed
>>scheduler is not working    -->your responsible for maintain this if using kops 
>>cluster upgradation
>>Learning Curve: Kops requires a good understanding of both Kubernetes and AWS. If your team is not familiar with these technologies, there might be a steep learning curve, which can lead to
misconfigurations and issues in a production environment.
>>Limited Cloud Provider Support: While Kops primarily focuses on AWS, support for other cloud providers like Azure and Google Cloud is not as robust. This can limit your options for multi-cloud 
or hybrid cloud strategies.
>>Maintenance Overhead: Managing Kubernetes clusters using Kops requires ongoing maintenance. You need to keep Kops itself updated along with the Kubernetes versions. This involves understanding 
the compatibility matrix, testing updates, and performing rolling updates of the clusters.

218-how to create a highly managed kubernetes cluster and worker nodes

>>if you use eks and aws fargate then this will help high availbility
>>fargate will serverless this will managed by AWS if you use EKS this will also manage AWS 
>>if you use fargate no need to manage anything if you install ec2 manaually you need to maintain the worker node like auto-scaling

219-what is the drawbacks in EKS

>>High cost
>>complexity hybrid environment
>>Troubleshooting challenges
>>Limited Node Instance Types
>>Delayed kubernetes version updates
>>cluster scaling limits
>>vendor lock-in
>>complex networking
>>Control and Customization

220-what is the Advanatges of EKS

>>managed service
>>Global Reach
>backup and restore
>>Integration with AWS Services
>>Managed Node Groups
>>Built-in Monitoring and Logging
>>Security and Compliance
>>scalibility 
>>Easy Setup
>>High Availbility

>>if your created 100 service then you created 100 load-balancers in eks or kops that will charge high then use ingress it will reduce the cost  
>>for example if you use 100 load-balancers in kubernetes you need to route then add that 100 load-balancers into route53 then if you use one ingress will create the load-balancer 
in aws then route that using route53 in sigle load-balancer you can create number of service it will balance the load 

221-types of Ingress-controller

1-Nginx-ingress
2-HA-Proxy 
3-Envoy-proxy
4-Istio
5-TrefiK
6-F5 conatiner ingress
7-GCp ingress
8-Ambassador
 
222-what is Ingress class

>> Using ingress class you can define watch for ingress resource

223-what are the causes of pod is pending status

1-Taints and tolerations
2-pod affinity or node affinity
3-network issues
4-resource quota
5-image in private

224-how to run specific user in kubernetes yaml with user id 1000

apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
  - name: my-container
    image: your-image:tag
    securityContext:
      runAsUser: 1000

225-how to see the Kubernetes API-server url or Cluster URL

>>kubectl cluster-info     -->this will show the server information include API server endpoint.
>>kubectl config view --minify -o jsonpath='{.clusters[0].cluster.server}'

226-how to create the eks cluster using cmd

>>sudo eksctl create cluster --name anji --region ap-south-1 --node-type t2.micro --nodes-min 1
>>aws eks update-kubeconfig --name anji --region ap-south-1    -->update the kubeconfig file

226-how to create helm charts how to pass the values or data 

>>cloudwithsiva session 75 45 mins time 
>>create chart folder 
>>mkdir chart 
>>cd chart
>>mkdir templates
>>vi charts.yaml 
apiVersion: v2
name: roboshop
version: 1.0
:wq

>>cd templates 
>>vi pods.yaml 
>>vi service.yaml  
>>helm install anji ./charts  --set component=cart  -->we are passing the variable to pods and service yaml why because if you eant excute 10 service no need to change everytime you cna send like this values  
>>cd ../..
>>vi frontend.yaml 
>>vi catalogue.yaml 
>>vi cart.yaml 
>>cd ..
>>helm install cart ./charts -f cart.yaml 
>>helm install frontend ./charts -f frontend.yaml 
>>helm upgrade -i anji  ./charts -f cart.yaml 
cart.yaml inside have variable that will point pod or service.yaml if you use single pod or service file then we pass the -f  cart.yaml have cart image if you use frontend.yaml then have frontend image or port 

>>helm create anji   -->it will create the anji helm inside the files wil create automcatically

227-if you have situvation like your need to expose the data into password or username like into pod  

>>you can use init container then you mount emptydir volumes then you then create one file store then another pod will use that data dont use EBS volumes it will not transfer or not good once you can check 

vi run.sh 
set -e

aws ssm describe-parameters --region us-east-1 --query "Parameters[*].Name" | xargs -n1  |sed -e 's/,//' | grep ${ENV}.${COMPONENT} >/parameter-store/names

rm -f /parameter-store/params

for param in `cat /parameter-store/names`; do
  VALUE=$(aws ssm get-parameters --region us-east-1 --names $param  --with-decryption --query Parameters[0].Value | sed 's/"//g'  )
  KEY=$(echo $param | awk -F . '{print $NF}')
  echo export $KEY=\"$VALUE\" >>/parameter-store/params
  cat /parameter-store/params
done
:wq   ##it will fetch the parameter store to collect the values ex: name=prod.catalogue.MONGO_URL value=mongo:hjahbjkhbj:ddjh
so if use the script it will collect the name filed MONGO_URL only then export the value MONGO_URL=value then teh value taken by that pod 
vi Dockerfile 

FROM amazonlinux/aws-cli  #this will install aws cli this have aws access with kubernetes server  
COPY          run.sh /
ENTRYPOINT    [ "bash", "/run.sh" ]

>>docker build -t anji .
>>then using this image you can do init container then it wil fetch that image one condition you need to pass the env and componnet variable if you use helm this is the command
stage('Helm Deploy') {
      steps {
        sh 'helm upgrade -i ${COMPONENT} ./HELM -f APP/values.yaml --set-string image.tag="${APP_VERSION},ENV=prod,COMPONENT=${COMPONENT}"'
      }
}

apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: main-container
        image: nginx:tag
        # Main application container configuration goes here
      initContainers:
      - name: init-container
        image: anji 
        commad: sleep ["10000"]
        env:
          - name: ENV 
            value: ENV
          - name: Component 
            value: Component

228-can i add multiple init containers in deployment or pod 

>>yes you can add multiple init containers the use case if you want execute the some schemas in database and pass the passwords like this you can use this  

229-explian this helm

>>helm init anji 
>>ls
templates -->diretory
deployment.yaml
hpa.yaml 
ingress.yaml
notes.txt 
service.yaml
serviceaccount.yaml
>>cd ../..

>>git clone https://github.com/teamall574/cart.git 
>>cd cart 
>>ls
values.yaml 
>>cd ..
>>mkdir app  -->for example you think cart inside app folder under values.yaml is there 
dir('APP') {
  git branch: 'main', url: 'https://github.com/raghudevopsb70/${COMPONENT}.git'
}
>>helm upgrade -i cart -f app/values.yaml --set-string=image.tag=${APP_Version}-->it wil replace anji helm chart under values.yaml 
parameters {
    string(name: 'COMPONENT', defaultValue: '', description: 'Component')
    string(name: 'APP_VERSION', defaultValue: '', description: 'App Version')
}   -->this replacing in APP_Version and tag in jenkins you giving either cart image or catalogue image like this many what you want 
>>if you want where the helm repository you wnat execute that means you can choose like this  
steps {
        dir('APP') {
          git branch: 'main', url: 'https://github.com/raghudevopsb70/${COMPONENT}.git'
        }
        dir('HELM') {
          git branch: 'main', url: 'https://github.com/raghudevopsb70/roboshop-helm-chart'
        }
      }
stage('Helm Deploy') {
      steps {
        sh 'helm upgrade -i ${COMPONENT} ./HELM -f APP/values.yaml --set-string image.tag="${APP_VERSION},ENV=prod,COMPONENT=${COMPONENT}"'
      }

    }

230-if you have two container how you can exec into first second like this 

apiVersion: v1 
kind: pod 
metadata:
  name: anji 
spec:
  containers:
  - image: nginx 
    name: nginx 
    volumeMounts:
    - mountPath: /cache 
      name: cache-volume 
  - image: centos:8
    name: centos 
    command: ["sleep", "10000"]     
    - mountPath: /cache 
      name: cache-volume 
  volumes:
  - name: cache-volume
    emptyDir:
      sizelimit: 500Mi

>>kubectl get pods
anji 
>>kubectl exec -it anji -c nginx -- bash  -->it will go into nginx 
>>kubectl exec -it anji -c centos -- bash  -->it will go into centos  

231-how to pass the passwords to kuberneets pods from AWS accounts

apiVersion: v1
kind: Pod
metadata:
  name: cart
spec:
  initContainers:
  - name: init-container
    image: amazonlinux:latest  # You can use an image that includes the AWS CLI
    env:
    - name: URL
      valueFrom:
        secretKeyRef:
          name: aws-ssm-secret
          key: url
    - name: PORT
      valueFrom:
        secretKeyRef:
          name: aws-ssm-secret
          key: port
    command: ["/bin/sh", "-c"]
    args:
    - |
      export URL=$(aws ssm get-parameter --name "/path/to/url" --query "Parameter.Value" --output text)
      export PORT=$(aws ssm get-parameter --name "/path/to/port" --query "Parameter.Value" --output text)
  containers:
  - name: cart-container
    image: your-cart-image
    env:
    - name: URL
      valueFrom:
        fieldRef:
          fieldPath: metadata.annotations['url']
    - name: PORT
      valueFrom:
        fieldRef:
          fieldPath: metadata.annotations['port']

232-what is OIDC 

>>video 79 26 mins 

233-what is RTO and RPO 

81 session 51 mins 
>>Recover Point:- 
>>Recover Time:-

234-how to add shortcuts or alias in permanent in linux 

vi .bash_profile

alias  ku="kubectl"
alias  ta="terrfform apply"
:wq
>>ku will use like this instead of kubectl we can use like this 
ku apply -f anji.yaml 
like this terrafrom 
ta -auto-approve 

235-what is epoch converter

>>it is database or any server will give you like this 1677718193 then you can convert normal time epoch converter using  

236-IF prometheus goes down how to montior the k8s

>>If the Prometheus monitoring system goes down in a Kubernetes cluster, there are alternative ways to monitor the cluster.
1-Grafana: Grafana is a popular open-source visualization and monitoring tool that can be integrated with various data sources, including Prometheus. You can set up Grafana to directly scrape metrics from Kubernetes components and display them in customizable dashboards.
2-Kubernetes Dashboard: Kubernetes provides a built-in web-based dashboard that allows you to view and manage cluster resources. It provides basic monitoring capabilities, such as displaying the status of pods, nodes, and deployments.
3-Heapster: Heapster is an older monitoring tool for Kubernetes that has been replaced by the Kubernetes Metrics Server. However, if Prometheus is down, you can still use Heapster as a fallback option. Heapster collects metrics from various sources and can be integrated with Grafana for visualization.
4-External Monitoring Services: You can also consider using external monitoring services like Datadog, New Relic, or Sysdig. These services provide comprehensive monitoring solutions and can integrate with Kubernetes to collect and display metrics.
>>you can use thanos or any external tools like elk like this 

237-what are the build issue will face in production environment in ci cd process

1-Dependency conflicts: When different components of an application have conflicting dependencies, it can lead to build failures or runtime errors. This can happen when different teams or individuals use different versions of libraries or frameworks.
2-Environment inconsistencies: Build issues can occur if the development and production environments are not aligned. For example, if the production environment lacks necessary system libraries, configurations, or environment variables, the build may fail.
3-Resource limitations: In some cases, the production environment may have limited resources such as memory, CPU, or disk space. This can cause build failures if the build process exceeds the available resources.
4-Network connectivity issues: If the build process relies on external services or dependencies, network connectivity problems can cause failures. This can happen if the network is slow, unstable, or if the external services are down.
5-Security restrictions: Production environments often have stricter security measures in place compared to development environments. Build processes that require elevated privileges, access to specific resources, or external network access may be blocked or restricted, leading to build failures.
6-Environment Discrepancies:
Operating System Differences: Development and production environments may use different operating systems.
Library/Dependency Versions: Discrepancies in library or dependency versions can lead to unexpected behavior.
Configuration Management:
Misconfigured Environment Variables: Inconsistent or missing environment variables can cause the application to behave differently.
Incorrect Configuration Files: Issues with configuration files, such as pointing to the wrong databases or API endpoints, can occur.
Database Migrations:
Data Schema Changes: Changes in the database schema that are not properly handled can cause data inconsistencies or application failures.
Resource Limitations:
Insufficient Resources: Production environments might have different resource constraints compared to development environments, leading to performance issues or crashes.
Security Considerations:
Security Configuration: Misconfigurations related to security settings, permissions, or firewall rules can compromise the application's security.
Networking Issues:
Firewall and Port Configuration: Firewalls or network policies might block the necessary ports, leading to connectivity issues between services.
DNS Resolution: Problems with domain name resolution can affect service discovery and communication.
Build Tool and Dependency Management:
Artifact Compatibility: Ensure that the artifacts generated in the CI process are compatible with the production environment.
Artifact Storage and Retrieval: Issues related to storing and retrieving artifacts from a repository can occur.
Versioning:
Inconsistent Versioning: Ensure that the versioning of the application, libraries, and dependencies is consistent across environments.
Rollback Mechanism:
Failure to Rollback: In the event of a deployment failure, having a robust rollback mechanism is crucial. Failing to rollback successfully can lead to downtime.
Monitoring and Logging:
Inadequate Monitoring: Lack of proper monitoring and logging can make it challenging to identify and troubleshoot issues quickly.
Scaling Challenges:
Auto-Scaling Issues: If the application relies on auto-scaling, ensure that it can scale up and down seamlessly based on demand.

238-elk have three component

>>elasticsearch uses KQL language:-Kibana Query Language (KQL) is a powerful tool to explore your data and discover patterns, identify anomalies and outliers, create statistical modeling, and more. 
1-kibana:-it is dashboard. It is a UI for users search the data in Elastisearch 
2-elastisearch:-it is database. It is a Database, Creates and index of words and allows users to retrive information over HTTP   
3-logstash:-it log-aggreator.logstash It is used converts the unstructured data to structured data  
4-beats:-it is used install in each and every system collect teh logs . filebeats collects the data and it can send it to either logstash or directly to elastic seatch 

filebeast-->logstash-->elastisearch-->kibana-->users we can acccess from ui through dashboard 

>> two type of data 
1-structured data:-
{
  "level": "INFO"
  "message": "Hello World"
  "date": "2020-10-05"
}
2-unstructured data:- 
2020-10-05 - INFO - Helllo World 

239-what is drokdebugger

>>video 65 32 mins see how create search for keywords in elasticsearch
>>it is used convert Elastisearch to easy way using some patterns you need add this pattern in 
>>vi /etc/logstash/conf.d/logstash.conf 

>>this apptern using you can easily understand teh data from elasticsearch dashboard if you cant added this elasticsearch you difficult understand teh data 
fileter {
  grok {
    match => { "message" => "%{IP:Source_IP}%{SPACE}-%{SPACE}\[%{HTTPDATE}\]%{GREEDYDDATA:all_data}" }
  }
}

240-is this possible to change the log format in nginx logs 

>>yes you can see video 65 40 mins how to change
>>vi /etc/nginx/nginx.conf 

log_format main 'remote_addr $time_local $request $status $body_bytes_sent $request_time'  
>>this format used to collect required information ex: you have send the data elk you can search easily what you want 

241-what is elk slove 

>>errors and traffic add also logs will store and also you can see the latency using visualize llibrary 
>>how muh traffic is comming 

242-what are best practice for deploying monothic application 

#>>so if you have 15 service divided your application use each microservice as one server ex: 15 micro service then use 15ec2 
#>>use private ips for internal communcation dont use private ips it will change
#>>developers choose application stack(whether to use java or nodejs or golang)
#>>developers chooses which version of software to be used 

243-what are the best practice for deploying microservice in kubernetes 

>>Deploying microservices in Kubernetes involves various considerations to ensure scalability, reliability, and maintainability. Here are some best practices for deploying microservices in Kubernetes:

Containerization:

Use containerization (e.g., Docker) to package your microservices along with their dependencies, making it easier to deploy and manage in Kubernetes.
Single Responsibility Principle:

Follow the Single Responsibility Principle for microservices. Each microservice should have a specific business function and should be responsible for a well-defined set of tasks.
Decomposition:

Break down your application into smaller, manageable microservices. Avoid creating overly large microservices that defeat the purpose of the microservices architecture.
Service Discovery:

Use Kubernetes service discovery mechanisms (e.g., Kubernetes Services or ExternalName Services) to allow microservices to discover and communicate with each other.
Configurations:

Externalize configuration settings using ConfigMaps or Secrets in Kubernetes. Avoid hardcoding configurations within the microservices.
Health Checks and Readiness Probes:

Implement health checks and readiness probes to help Kubernetes manage the lifecycle of your microservices. This ensures that only healthy instances receive traffic.
Secrets Management:

Manage sensitive information such as passwords and API keys using Kubernetes Secrets. Avoid storing sensitive information directly in your application code or configuration files.
Resource Requests and Limits:

Define resource requests and limits for CPU and memory in your Kubernetes Deployment or Pod specifications. This helps Kubernetes scheduler make better decisions about where to place your microservices and prevents resource contention.
Horizontal Scaling:

Leverage Kubernetes Horizontal Pod Autoscaling to automatically adjust the number of replicas based on metrics such as CPU utilization or custom metrics.
Logging and Monitoring:

Implement centralized logging and monitoring using tools like Prometheus, Grafana, or ELK stack. This facilitates easy debugging, performance analysis, and issue resolution.
Rolling Updates:

Use rolling updates for deploying new versions of your microservices to ensure zero downtime. Kubernetes allows you to gradually replace old instances with new ones.
Load Balancing:

Use Kubernetes Services for load balancing across instances of your microservices. This helps distribute traffic evenly and ensures high availability.
Namespace Isolation:

Consider using Kubernetes namespaces to isolate and organize resources. This is especially useful in multi-tenant environments.
Backup and Restore:

Regularly back up your application data, and have a strategy for restoring data in case of failures. Kubernetes Persistent Volumes (PVs) and Persistent Volume Claims (PVCs) can be used for stateful applications.
Security Policies:

Implement Kubernetes Network Policies to control the communication between microservices and enhance the security of your application.
Immutable Infrastructure:

Treat your infrastructure as immutable. Avoid making changes directly to running instances; instead, redeploy with the desired changes.

244-whar are the big challenges in micro-services

1-networking 
2-load-balancing
3-Identity of services 
4-
246-is there any dashboard tool availble for kubernetes 

>>yes there is tool called octant install this or see cloudwithsiva 73 session 9 mins
https://github.com/vmware-archive/octant/releases
sudo mv /path/to/downloaded/octant /usr/local/bin/octant
sudo chmod +x /usr/local/bin/octant
octant
octant --listener-addr 0.0.0.0:7777
>>nohup octant --listener-addr 0.0.0.0:7777 &  -->this will run background 
then add this into nginx reverse proxy nginx.conf file then you can access  

and one more is k9s and k8s dashboard and lens tool also 

249-what is status: {}  in kubernetes yaml file 

>>The status section is where the Kubernetes system provides the current observed state of the resource.

250-what is containerd in kubernetes 

>>containerd is an industry-standard core container runtime used in various container orchestration platforms, including Kubernetes. It is designed to be a lightweight and focused container runtime, providing the essential functionality needed to run containers. containerd is part of the larger container ecosystem and serves as a building block for container platforms.
>>containerd is a container runtime, responsible for the execution of containers on a host system.
>>container runtime use containerd to run the containers 

251-what is cluster 

>>a group of similar things or service is called cluster 

252-what are the policies you need to give eks cluster 

1-AWSCloudFormationFullAccess 
2-IAM Access 
3-Ec2 Full Access (load-balacing,cloudwatch,autoscaling,ec2 )
4-EksAllAccess
kops S3 access (if you use kops IAM,S3,EC2,Route53 )

253-how to pass the secret manager credential to jenkins pipeline 

>>

254-how to check the pod logs of kubernets using grafana dashboard 

>>Configure Data Source in Grafana:

Access your Grafana dashboard and configure Loki as a data source.
Go to Configuration -> Data Sources -> Add data source.
Choose Loki from the list of available data sources and provide the necessary connection information (Loki URL, etc.).
Querying Logs:

Once Loki is configured as a data source, go to the Explore section in Grafana.
In Explore, you can write PromQL (Prometheus Query Language) or LogQL (Loki Query Language) queries to filter and search for logs.
For example, to view logs from a specific pod, you can use a query like:
plaintext
Copy code
{namespace="your-namespace",pod="your-pod-name"}
Modify the query based on your specific criteria such as namespace, pod name, time range, etc.
Visualize Logs:

Grafana allows you to create visualizations and dashboards based on the logs you've queried. You can create panels that display log lines, count log entries, visualize trends, and more.
Create a new dashboard, add a panel, and configure the panel to display the log data obtained from Loki queries.
Save and Monitor:

Save your Grafana dashboard with the configured panels for future reference.
You can set up alerts and notifications based on log data, allowing you to monitor specific events or patterns in your pods' logs.

255-how to find out the DNS name in svc or deployment in kubernetes

>>kubectl get service <service-name> -n <namespace> -o=jsonpath='{.status.loadBalancer.ingress[0].hostname}'
>>kubectl get service <service-name> -n <namespace> -o=jsonpath='{.status.loadBalancer.ingress[0].ip}'

>>kubectl get pod -l app=<deployment-label> -o=jsonpath='{.items[0].spec.hostname}' -n <namespace>

256-what is mean by -it in docker or kubernetes

>>it is like it-->means interactive 
>>docker exec -it xxxxxx or kubectl exec -it xxxx 

257-what are the servics in kubernetes

1-clusterIp
2-NodePort
3-Load-blancer
4-ExternalName 

258-what are security standards in deploying application 

1-Run application as normal user 
2-Never login as root user 
3-authentication and authrizations will be give properly
4-Data Encryption 
5-secure code and check vulnerability scaning 
6-secure APIS 
7-logging and monitoring
8-patch regularly 
9-Disaster Recovery and backups 
10-secure deployment pipelines 

259-how we can assign the values to pod mb cpu calculation

1000  = 1 cpu
1000  = 1gb memory
in request means you requested 100m cpu then definetly you will get. like this if you given limit 500m menas if will not gurante if the cpu is available then it will give otherwise dont give 

