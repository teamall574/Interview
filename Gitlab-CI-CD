##on runner system need to install the maven and docker also if not installing it will not work
Image: "abhishekf5/maven-abhishek-docker-agent:v1" #this used as docker agent no need to install maven in your ec2 it will execute the maven commands

variables:
  SONAR_HOST_URL: https://34.203.223.11.9000
  SONAR: ${SONAR_LOGIN}
  SLACK_CHANNEL: ${slack-token}

before_script:
  - cd java-maven-sonar/spring-boot-app   ##if your project inside the directory you can use like this before executing your script

Stages:
  - compile
  - Sonarqube-analysis
  - build
  - image
  - deploy
Compile-job:
  stage: compile
  tags: 
    - "self-hosted"
  script:
    - echo "compiling code"
    - mvn clean package
sonarqube-job:
  stage: sonarqube-analysis
  script:
    - echo "Running sonarqube Analysis"
    - mvn sonar:sonar -Dsonar.host.url=${SONAR_HOST_URL} -Dsonar.login=${SONAR_LOGIN}
  artifacts:
    paths:
      - target/*.war
    - mvn deploy -Dmaven.deploy.skip=true -Dmaven.artifact.threads=2 ##or else you can setting.xml username and password and add pom.xml in url pass variables
    only:
      - master
build-job:
  stage: build
  tags: 
    - "self-hosted"
  script:
    - echo "Maven Build"
    - mvn clean install
deploy-job:
  stage: image
  image: docker:stable
  services:
    - docker:dind
  tags:
    - "self-hosted"   ##runner name label what you given"
  script:
    - echo "buidl docker image and push"
    - docker build -t kubetest .
    - docker login -u $DOCKER_USERNAME -p $DOCKER_PASSWORD
    - docker tag kubetest $DOCKER_USERNAME/kubetest:latest
    - docker push anji1592/kubetest:latest
deploy-image:
  stage: deploy
  tags:
    - "self-hosted"   ##runner name label what you given"
  scripts:
    - kubectl create -f anji.yml
    - kubectl create -f service.yml
  only:
   - master
send_slack_notification:
  stage: build
  script:  ##need to add slack your token in SLACK_WEBHOOK_URL
    - 'curl -X POST -H "Content-type: application/json" --data "{\"text\":\"Build is successful for project: $CI_PROJECT_NAME\"}" $SLACK_WEBHOOK_URL'
  only:
    - master  # Change this to a branch or tag that you want to trigger the notification
  when: on_success




1-What is Gitlab

>>GitLab is a web tool to assist with visualizing and managing your git projects. GitLab includes Git repository management, code reviews, issue tracking, wikis, and more. Collaborate with your team using issues, milestones, and line-by-line code review or view activity streams of projects or the people you work with.

>>Git and GitLab are here to help with managing projects, merging development between different people, with different time zones, and giving Sealed Air the ability to manage all of its source code in 1 location.

2-When Should I Consider Gitlab?

>>Version control software, like Git, allows you to have “versions” of a project, which show the changes that were made to code, or text files, over time, and allows you to backtrack if necessary and undo those changes or merge your code with others, line by line.

3-Is it possible to Host the Gitlab in local environment

>>You should manually download the GitLab package and relevant dependencies using a server of the same operating system type that has access to the Internet. If your offline environment has no local network access, you must manually transport the relevant package through physical media, such as a USB drive.

4-What is the minimum RAM for GitLab?

>>Memory. You need at least 2GB of addressable memory (RAM + swap) to install and use GitLab! With less memory GitLab will give strange errors during the reconfigure run and 500 errors during usage. 512MB RAM + 1.5GB of swap is the absolute minimum but we strongly advise against this amount of memory.

5-Disadvantages of Gitlab

>>Even if GitLab is simple to use, it’s a big piece of software that can sometimes become slow on the web user interface. Moreover, the review system is sometimes not so easy to use compared to other competitors.

6-What is GitLab used for?

>>GitLab is a management platform for Git repositories that provides integrated features like continuous integration, issue tracking, team support, and wiki documentation.

7-Advantages of Gitlab

>>The significant advantage of GitLab is it is available for free and easy to manage and configure it. it enables only a limited number of private repository, integrate several API and third-party server and consume only a reliable uptime. The code reviews and pulls up requests made it more compact and user-friendly.
1-Manage
2-plan
3-Create
4-Verfiry
5-package
6-Secure
7-Release
8-Configure
9-montior

8-What is Gitlab Runner

>>Gitlab Runner is an application that pick up and execute CI?CD jobs for Gitlab
>>Gitlab Runner is open-source
>>there are two types
1-Specific Runners(this will host by you)
2-Shared Runners(this will provide by gitlab)
>>you can install Gitlab Runner on several different supported operating systems&also can run inside Docker container

9-what is the Advantages of Docker Exectors or Docker Agents

>>if your using docker agents 
1-secuirty
2-configuration no need to configuration in all the systems everytime it is in light-weight in nature multiple pipelines parallel
3-you can run hundred of jobs using docker agents

10-how to secure the password and tokens in gitlab

>>there is option in settings under variables add your username or password or API-Tokens

11-Is it possible to do multiple jobs in a single stage

>>yes you can do 
build-job1:
  stage: build
  tags: 
    - "self-hosted"
  script:
    - echo "Maven Build"
    - mvn clean package
build-job2:
  stage: build
  tags: 
    - "self-hosted"
  script:
    - echo "Maven Build"
    - mvn clean install

12-Is it possible to do jobs running in parellel

>>yes you can do that by using this 
build-job:
  stage: build
  parallel: 10
  tags: 
    - "self-hosted"
  script:
    - echo "Maven Build"
    - mvn clean install

13-How to speeding up build or pipeline

>>using cache to speedup the build or pipeline
build-job:
  stage: build
  cache:
    key: $(CI_COOMIT_REF_SLUG)
    paths:
    - nodes_modules/  ##it is job level only
  tags: 
    - "self-hosted"
  script:
    - echo "Maven Build"
    - mvn clean install

14-Is it possible to copy artifacts into gitlab

>>yes it possible see below

build-job:
  stage: build
  artifacts:
    when: always
    expire_in: 1 Week  #it will hold the artifacts into only one week then after it will delete
    paths: 
      - package-lock.json
      - npm-audit.json
  tags: 
    - "self-hosted"
  script:
    - echo "Maven Build"
    - mvn clean install

15-if the build will fail when the artifacts will upload in gitlab

>>No by defalut it will not upload you can enable by using this syntax
build-job:
  stage: build
  artifacts:
    when: always
    paths: 
      - package-lock.json
      - npm-audit.json
  tags: 
    - "self-hosted"
  script:
    - echo "Maven Build"
    - mvn clean install

16-how to use artifacts in feature pipelines or projects

>>
build:
  stage: build
  script:
    - echo "I am an artifact" >anji.txt
  artifacts:
    paths: 
      - artifact.*

test:
  stage: test
  dependencies:
    - build
  script: 
    - cat artifact*.*

17-

=====================================================AWS-DevOps=================================================================================
1-What AWS CI/CD

>>AWS provides a comprehensive set of CI/CD(continous Integration/Continous Deployment) service that enable developers to automate
and streamline their software delivery process
1-AWS Code commit 
2-AWS Codepipeline
3-AWS CodeBuild
4-AWS CodeDeploy

2-what is Code commit in AWS

>>AWS CodeCommit is a secure, highly scalable, managed source control service that makes it easier for teams to collaborate on code. 
AWS CodeCommit eliminates the need for you to operate your own source control system or worry about scaling its infrastructure.

3-what is managed Git

>>people they download git they install git in local server or gitlab to host them self

>>AWS CodeCommit is a secure, highly scalable, managed source control service that makes it easier for teams to collaborate on code. 
AWS CodeCommit eliminates the need for you to operate your own source control system or worry about scaling its infrastructure.
>>AWS CodeCommit is compettion to who will provide private repos like github enterprise or gitlab 
>>your not able to clone the code using SSH by using Root account dont use root account dont recomended
>>it solves the problem of managed git solutions

Advanatges:-

>>This managed AWS Service or Private Repository
>>It makes private in Enterprise-level
>>It is Scalability
>>It is Reliability
>>Version-Control

Dis-Advantages:-

>>less featurres(code-pilot,like visual-studio,github-Actions,collabration)
>>AWS Restricted to AWS Service only dont allow multiple third party applications
>>Less Integrations with services outside AWS
>>User-Interface not good

4-what are the Code-commit policies you have

>>AWS CodeCommitFull-Access
>>AWS CodeCommitPowerUser
>>AWS CodeCommitRead-only

5-what is Code-Pipeline

>>AWS CodePipeline is a continuous delivery service you can use to model, visualize, and automate the steps required to release your software. You can quickly model and configure the different stages of a software release process. CodePipeline automates the steps required to release your software changes continuously.
>>you can Integrate the code commit and code build you can deploy your code into ECS or Docker or Ec2 like Integrate the GitOps or Ansible or kubernets system deploy your code 
>>compulsory need appsec.yml if you mention appsec.yaml it will not work use only appsec.yml

6-what is the differnce between Code-Pipeline and Jenkins

>>Code-Pipeline:-AWS CodePipeline is a managed CI/CD tool that provides integrated Amazon cloud DevOps tooling. CodePipeline is actually a suite of services. It combines CodeBuild, CodeDeploy and Git-based source code repository CodeCommit.

>>Even though CodePipeline is an AWS tool, it doesn't limit you to Amazon's cloud. You can use CodeDeploy for on-premises deployment by running agents on your private servers. If you're already running a CI tool inside your AWS environment, or have your code stored in GitHub or GitLab, you can also integrate such tools into CodePipeline and only use what you need. For example, you could use CodeDeploy to publish code onto your EC2 instances or Amazon Elastic Container Service containers.

>>Jenkins:-Jenkins is one of the most popular open source CI/CD tools. Although the project started as an automation server, the Jenkins community has developed more than 1,000 plugins for the tool. Jenkins can integrate with all public cloud providers and many applications that support developer work, such as GitLab, GitHub, Artifactory and HashiCorp Vault.

AWS CodePipeline vs. Jenkins

1-Cost:-
2-Usability:-
3-Integration:-

>>if you use jenkins you need to implement the salves that will charge your your slaves need to run everytime when your to build the code you dont
in this place you can use code build it will help you less cost how much you build that will charge . you have to manage the slaves and nodes 
you have patching and upgrading need one dedicated AWS person if you use AWS Codepipeline AWS will manage this services it will charge accordingly
or you can use docker agents as slaves in jenkins and also youe configure auto-scaling and stoarge and load-balancer and cloudwatch this will already managed by default you can setup easy
if your not managing efffciently the cost will increase

>>The major drawback they very much restricted to AWS Only 

Though we can use all of above then what is the use of code pipeline?
AWS CodePipeline is a fully managed continuous delivery service that automates the build, test, and deployment of applications. It allows you to create and visualize a pipeline that integrates various tools and services, such as source code management, continuous integration, and deployment.

The main benefit of using AWS CodePipeline is that it provides a centralized way to manage and automate the end-to-end software delivery process. It enables you to configure a pipeline that is tailored to your specific requirements, and automate the testing and deployment of your code changes, ensuring that your application is released with quality and consistency.

By using AWS CodePipeline, you can speed up your software delivery process, reduce manual errors, and increase the overall efficiency and productivity of your development team.

In Code-Deploy what file we used to write the pipeline

>>Buildspec.yml  -->then we can write pipeline how to build the code

##add credentials in systems manager select the parameter store add docker username password and url
/myapp/docker-credentials/username/
anji1592
/myapp/docker-credentials/password/
test
/myapp/docker-credentials/docker_url/
docker.io


version: 0.2
env:
  parameter-store:
    docker_registery_username: /myapp/docker-credentials/username/
    docker_registery_password: /myapp/docker-credentials/password/
    docker_registery_docker_url: /myapp/docker-credentials/docker_url/
    LOGIN: /myapp/sonarqube/token/
    HOST: /myapp/sonarqube/url/
    PROJECT: /myapp/sonarqube/anji
    ORGANIZATION: /myapp/sonarqube/test
phases:
  install:
    runtime-versions:
      java: corretto11
      docker: 19  
      python: 3.79
  pre_build:
    commands: 
      - pip install -r requirements.txt   ##it will install before the build
      - apt-get install -y maven
      - mvn --version
      - echo "Installing Trivy..."
      - wget https://github.com/aquasecurity/trivy/releases/download/v0.20.0/trivy_0.20.0_Linux-64bit.deb
      - dpkg -i trivy_0.20.0_Linux-64bit.deb
      - trivy --version
      - $(aws ecr get-login --no-include-email --region <your-ecr-region>)

  build:
    commands:
      - cd day14/anji
      - mvn clean install
      - sonar-scanner -Dsonar.login=$LOGIN -Dsonar.host.url=$HOST -Dsonar.projectkey=$PROJECT -Dsonar.organization=$ORGANIZATION
      - sleep 5
      - mvn deploy -Dmaven.test.skip=true -Dmaven.deploy.skip=true \
          -DaltDeploymentRepository=nexus::default::<nexus-repo-url> \
          -DrepositoryId=nexus-repo -s settings.xml
      - echo "build docker image"
      - echo "$docker_registery_username" | docker login -u "$docker_registery_username" --password-stdin "docker_registery_docker_url"
      - docker build -t "$docker_registery_docker_url/docker_registery_username/test:latest" .
      - docker build -t "docker.io/anji1592/test:latest" .
      - docker push "$docker_registery_docker_url/docker_registery_username/test:latest"
      - trivy anji1592/test:latest
      - echo "Building Docker image..."
      - docker build -t <your-ecr-repo-url>/<image-name>:<tag> .

      - echo "Pushing Docker image to ECR..."
      - docker push <your-ecr-repo-url>/<image-name>:<tag>
  post-build:
    commands:
      echo "build is succesfully" 
